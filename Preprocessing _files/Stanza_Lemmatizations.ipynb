{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stanza_Lemmatizations.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxAg5Bzfmoa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
        "# doc = nlp('Meural Networks')\n",
        "# lemmatized_chunk = \"\"\n",
        "# for sent in doc.sentences:\n",
        "#   for word in sent.words:\n",
        "#     lemmatized_chunk = lemmatized_chunk + word.lemma\n",
        "\n",
        "# print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZe88XNKGlel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "c4fe6d0f-75fd-4f07-83d8-a26d38d78f5b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-636f7e70c0f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    240\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEns1jktbDjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99ee693d-89a5-4ce9-d435-01bc13abf874"
      },
      "source": [
        "!pip install stanza\n",
        "import stanza\n",
        "stanza.download('en')\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stanza in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.5.1+cu101)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (49.1.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 11.1MB/s]                    \n",
            "2020-07-23 05:52:16 INFO: Downloading default packages for language: en (English)...\n",
            "2020-07-23 05:52:19 INFO: File exists: /root/stanza_resources/en/default.zip.\n",
            "2020-07-23 05:52:25 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (49.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (49.1.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC9nbss5J_aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first appproach lemma here\n",
        "#jalaj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xCW4gGGi_ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pta89B8PY_ZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/data_final_2 - Copy.csv\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stoplist = stopwords.words('english')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "from nltk.tokenize import MWETokenizer\n",
        "tokenizer = MWETokenizer()\n",
        "#tokenizer.add_mwe('a', 'study', 'to')\n",
        "\n",
        "\n",
        "tokenized_doc = data[\"project\"].apply(lambda x: tokenizer.tokenize(x.lower().split()))\n",
        "# remove stop-words\n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26UgTskif-Y6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "096060ce-c547-475e-e3a9-2a757e4d47dd"
      },
      "source": [
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "\n",
        "import itertools\n",
        "words = list(itertools.chain.from_iterable(tokenized_doc))\n",
        "\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "bcf = BigramCollocationFinder.from_words(words)\n",
        "\n",
        "#filter_stops = lambda w: len(w) < 3 or w in new_stopwords_list\n",
        "filter_stops = lambda w: w in stop_words\n",
        "bcf.apply_word_filter(filter_stops)\n",
        "\n",
        "bcf.nbest(BigramAssocMeasures.likelihood_ratio, 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('machine', 'learning'),\n",
              " ('deep', 'learning'),\n",
              " ('neural', 'network'),\n",
              " ('convolutional', 'neural'),\n",
              " ('computer', 'vision'),\n",
              " ('natural', 'language'),\n",
              " ('jupyter', 'notebook,'),\n",
              " ('logistic', 'regression,'),\n",
              " ('technologies', 'used:'),\n",
              " ('random', 'forest,'),\n",
              " ('colab,', 'matplotlib,'),\n",
              " ('matplotlib,', 'seaborn.'),\n",
              " ('python,', 'jupyter'),\n",
              " ('google', 'colab,'),\n",
              " ('seaborn.', 'successfully'),\n",
              " ('notebook,', 'google'),\n",
              " ('state', 'art'),\n",
              " ('data', 'set'),\n",
              " ('random', 'forest'),\n",
              " ('achieved', 'accuracy'),\n",
              " ('exploratory', 'data'),\n",
              " ('data', 'cleaning,'),\n",
              " ('raspberry', 'pi'),\n",
              " ('neural', 'networks'),\n",
              " ('language', 'processing'),\n",
              " ('successfully', 'achieved'),\n",
              " ('decision', 'tree,'),\n",
              " ('see', \"project'\"),\n",
              " ('algorithms', 'technologies'),\n",
              " ('time', 'series')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlCr8LQ6jas5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "621c07f5-821d-4fc5-9ccd-5eeacddd4975"
      },
      "source": [
        "\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "tcf = TrigramCollocationFinder.from_words(words)\n",
        "tcf.apply_word_filter(filter_stops)\n",
        "tcf.apply_freq_filter(3)\n",
        "tcf.nbest(TrigramAssocMeasures.likelihood_ratio, 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('convolutional', 'neural', 'network'),\n",
              " ('recurrent', 'neural', 'network'),\n",
              " ('using', 'machine', 'learning'),\n",
              " ('convolution', 'neural', 'network'),\n",
              " ('using', 'deep', 'learning'),\n",
              " ('machine', 'learning', 'algorithms'),\n",
              " ('various', 'machine', 'learning'),\n",
              " ('machine', 'learning', 'techniques'),\n",
              " ('deep', 'neural', 'network'),\n",
              " ('neural', 'network', 'classify'),\n",
              " ('deep', 'learning', 'model'),\n",
              " ('used', 'deep', 'learning'),\n",
              " ('python,', 'jupyter', 'notebook,'),\n",
              " ('natural', 'language', 'processing'),\n",
              " ('jupyter', 'notebook,', 'google'),\n",
              " ('notebook,', 'google', 'colab,'),\n",
              " ('convolutional', 'neural', 'networks'),\n",
              " ('colab,', 'matplotlib,', 'seaborn.'),\n",
              " ('matplotlib,', 'seaborn.', 'successfully'),\n",
              " ('google', 'colab,', 'matplotlib,')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPbmDHZgHXKm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "175d71e8-4d84-423e-da4f-12f893871938"
      },
      "source": [
        "#jalaj \n",
        "bigrams = bcf.nbest(BigramAssocMeasures.likelihood_ratio, 12)\n",
        "trigrams = tcf.nbest(TrigramAssocMeasures.likelihood_ratio, 6)\n",
        "ngrams = bigrams + trigrams + [(\"sentiment\",\"analysis\"), \n",
        "                               ('naive', 'bayes'),\n",
        "                                ('breast', 'cancer'),\n",
        "                                ('time', 'series'),\n",
        "                                ('android', 'app'),\n",
        "                               ('f', 'score')] \n",
        "\n",
        "\n",
        "ngrams"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9b4e6a4acc51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 \u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'series'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                 \u001b[0;34m(\u001b[0m\u001b[0;34m'android'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'app'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                ('f', 'score')] - []\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6RMQBlRm15O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c8c323a-88cc-4545-b587-c78c68a07930"
      },
      "source": [
        "#doc.noun_chunks Container\n",
        "\n",
        "# A Doc object’s doc.noun_chunks property allows us to iterate over the noun chunks in the document. \n",
        "# A noun chunk is a phrase that has a noun as its head. \n",
        "\n",
        "# Example for the phrase \" A noun chunk is a good phrase that has a noun as its head\"\n",
        "\n",
        "# 1. A noun chunk\n",
        "# 2. a good phrase\n",
        "# 3. a noun\n",
        "# 4. its head\n",
        "\n",
        "import time\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "import string\n",
        "import re\n",
        "from string import digits\n",
        "import pandas as pd\n",
        "\n",
        "nlp_1 = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
        "\n",
        "def clean_phrase(phrase):  \n",
        "    r = phrase\n",
        "    for i in r:\n",
        "        if i in string.punctuation:\n",
        "            if i!=\"-\":\n",
        "                r = r.replace(i,\"\")\n",
        "            else:\n",
        "                r = r.replace(i,\" \")\n",
        "    phrase = r   \n",
        "    # print(phrase)\n",
        "    # s will give the phrase with all the numbers removed\n",
        "    s = phrase\n",
        "    remove_digits = str.maketrans('', '', string.digits)\n",
        "    s = s.translate(remove_digits)\n",
        "    phrase = s\n",
        "\n",
        "    # print(phrase)\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))   \n",
        "    word_tokens = word_tokenize(phrase) \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w) \n",
        "#     print(word_tokens) \n",
        "#     print(filtered_sentence) \n",
        "    cleaned_chunk =  \" \".join(filtered_sentence)\n",
        "\n",
        "    # print(cleaned_chunk)\n",
        "    #no need to lemmetize here\n",
        "    #jalaj\n",
        "    try:\n",
        "      doc_1 = nlp_1(cleaned_chunk)\n",
        "      lemmatized_chunk = []\n",
        "      for sent in doc_1.sentences:\n",
        "        for word in sent.words:\n",
        "          lemmatized_chunk.append(word.lemma)\n",
        "      return \" \".join(lemmatized_chunk)\n",
        "    except:\n",
        "      print(f\"Oh Shit = {phrase}\")\n",
        "      return \"\"\n",
        "      \n",
        "\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/data_final_2 - Copy.csv\")\n",
        "df.columns = [\"label\", \"project\"]\n",
        "rawlist = list(df.project)\n",
        "\n",
        "items = len(rawlist)\n",
        "\n",
        "rawlist_shrinked = []\n",
        "\n",
        "for item in range(items):\n",
        "    if(len((rawlist[item].split()))<15):\n",
        "        # print(rawlist[item])\n",
        "        continue\n",
        "    else:\n",
        "        rawlist_shrinked.append(rawlist[item])\n",
        "\n",
        "items_2 = len(rawlist_shrinked)\n",
        "cleaned_documents = []\n",
        "\n",
        "for item in range(items_2):\n",
        "\n",
        "    # print(f\"Project {item}\")\n",
        "    text = rawlist_shrinked[item]\n",
        "    \n",
        "    lower_case = text.lower()\n",
        "    text = lower_case\n",
        "    # print(text)\n",
        "    doc = nlp(text)\n",
        "    phrase = \"\"\n",
        "    for chunk in doc.noun_chunks:\n",
        "        # print(chunk)\n",
        "        new = clean_phrase(str(chunk))\n",
        "        # print(new)\n",
        "        # new_ = new.replace(\" \", \"_\")\n",
        "        phrase = phrase + \" \" + new\n",
        "#         print(phrase)\n",
        "#         print(type(phrase))\n",
        "#         print(type(new_))\n",
        "        # print(new_)\n",
        "#         print(type(chunk))\n",
        "    \n",
        "    cleaned_documents.append(phrase)\n",
        "    # print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-23 05:52:54 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
            "2020-07-23 05:52:54 INFO: Loading these models for language: en (English):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ewt     |\n",
            "| pos       | ewt     |\n",
            "| lemma     | ewt     |\n",
            "=======================\n",
            "\n",
            "2020-07-23 05:52:54 INFO: Use device: cpu\n",
            "2020-07-23 05:52:54 INFO: Loading: tokenize\n",
            "2020-07-23 05:52:54 INFO: Loading: pos\n",
            "2020-07-23 05:52:55 INFO: Loading: lemma\n",
            "2020-07-23 05:52:55 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Oh Shit = itself\n",
            "Oh Shit = \n",
            "Oh Shit = we\n",
            "Oh Shit = they\n",
            "Oh Shit = who\n",
            "Oh Shit = it\n",
            "Oh Shit = them\n",
            "Oh Shit = who\n",
            "Oh Shit = it\n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = they\n",
            "Oh Shit = them\n",
            "Oh Shit = it\n",
            "Oh Shit = \n",
            "Oh Shit = them\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = what\n",
            "Oh Shit = he\n",
            "Oh Shit = it\n",
            "Oh Shit = \n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = it\n",
            "Oh Shit = \n",
            "Oh Shit = to \n",
            "Oh Shit = them\n",
            "Oh Shit = you\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = you\n",
            "Oh Shit = it\n",
            "Oh Shit = itself\n",
            "Oh Shit = you\n",
            "Oh Shit = itself\n",
            "Oh Shit = it\n",
            "Oh Shit = them\n",
            "Oh Shit = i\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = \n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = them\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = \n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = you\n",
            "Oh Shit = you\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = you\n",
            "Oh Shit = them\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = they\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = they\n",
            "Oh Shit = who\n",
            "Oh Shit = who\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = \n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit =  \n",
            "Oh Shit =  \n",
            "Oh Shit =  \n",
            "Oh Shit =  \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = them\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = he\n",
            "Oh Shit = them\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = them\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = who\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = them\n",
            "Oh Shit = you\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = you\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = who\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = them\n",
            "Oh Shit = they\n",
            "Oh Shit = who\n",
            "Oh Shit = them\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = them\n",
            "Oh Shit = they\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = who\n",
            "Oh Shit = them\n",
            "Oh Shit = i\n",
            "Oh Shit = he\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = you\n",
            "Oh Shit = i\n",
            "Oh Shit = them\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = \n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = them\n",
            "Oh Shit = i\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = them\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = what\n",
            "Oh Shit = them\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = themselves\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = them\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = over \n",
            "Oh Shit = we\n",
            "Oh Shit = they\n",
            "Oh Shit = they\n",
            "Oh Shit = they\n",
            "Oh Shit = they\n",
            "Oh Shit = who\n",
            "Oh Shit = them\n",
            "Oh Shit = they\n",
            "Oh Shit = what\n",
            "Oh Shit = what\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = itself\n",
            "Oh Shit = \n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = \n",
            "Oh Shit = you\n",
            "Oh Shit = it\n",
            "Oh Shit = you\n",
            "Oh Shit = you\n",
            "Oh Shit = you\n",
            "Oh Shit = it\n",
            "Oh Shit = you\n",
            "Oh Shit = it\n",
            "Oh Shit = you\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = what\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = you\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = who\n",
            "Oh Shit = it\n",
            "Oh Shit = them\n",
            "Oh Shit = them\n",
            "Oh Shit = i\n",
            "Oh Shit = you\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = they\n",
            "Oh Shit = \n",
            "Oh Shit = \n",
            "Oh Shit = itself\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = who\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = about   \n",
            "Oh Shit = they\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = \n",
            "Oh Shit = who\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = they\n",
            "Oh Shit = them\n",
            "Oh Shit = we\n",
            "Oh Shit = an am\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = you\n",
            "Oh Shit = you\n",
            "Oh Shit = yourself\n",
            "Oh Shit = you\n",
            "Oh Shit = you\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = who\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = me\n",
            "Oh Shit = she\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = them\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = them\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = over \n",
            "Oh Shit = them\n",
            "Oh Shit = we\n",
            "Oh Shit = them\n",
            "Oh Shit = it\n",
            "Oh Shit = them\n",
            "Oh Shit = them\n",
            "Oh Shit = it\n",
            "Oh Shit = i\n",
            "Oh Shit = \n",
            "Oh Shit = them\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = themselves\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = we\n",
            "Oh Shit = it\n",
            "Oh Shit = we\n",
            "Oh Shit = you\n",
            "Oh Shit = we\n",
            "Oh Shit = him\n",
            "Oh Shit = her\n",
            "Oh Shit = them\n",
            "Oh Shit = i\n",
            "Oh Shit = it\n",
            "Oh Shit = them\n",
            "Oh Shit = it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke_EPPEmpfqZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cdbf112-4cc7-4964-dd15-4e65370da905"
      },
      "source": [
        "# Streaming output truncated to the last 5000 lines.(google collab)\n",
        "# TO avoid the above error either store it in drive or print less lines.\n",
        "\n",
        "len(cleaned_documents)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "629"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfD3oqkJ5Wx3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b7dae5c-0f74-4492-c4bc-b28a1c0bfeff"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "710"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HzoBwK15SVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "5cd3c214-fd78-4eac-d6cb-5d0dd8079fe0"
      },
      "source": [
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "\n",
        "import itertools\n",
        "words = list(itertools.chain.from_iterable(tokenized_doc))\n",
        "\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "bcf = BigramCollocationFinder.from_words(words)\n",
        "\n",
        "#filter_stops = lambda w: len(w) < 3 or w in new_stopwords_list\n",
        "filter_stops = lambda w: w in stop_words\n",
        "bcf.apply_word_filter(filter_stops)\n",
        "\n",
        "bcf.nbest(BigramAssocMeasures.likelihood_ratio, 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('machine', 'learning'),\n",
              " ('deep', 'learning'),\n",
              " ('neural', 'network'),\n",
              " ('convolutional', 'neural'),\n",
              " ('computer', 'vision'),\n",
              " ('natural', 'language'),\n",
              " ('jupyter', 'notebook,'),\n",
              " ('logistic', 'regression,'),\n",
              " ('technologies', 'used:'),\n",
              " ('random', 'forest,'),\n",
              " ('colab,', 'matplotlib,'),\n",
              " ('matplotlib,', 'seaborn.'),\n",
              " ('python,', 'jupyter'),\n",
              " ('google', 'colab,'),\n",
              " ('seaborn.', 'successfully'),\n",
              " ('notebook,', 'google'),\n",
              " ('state', 'art'),\n",
              " ('data', 'set'),\n",
              " ('random', 'forest'),\n",
              " ('achieved', 'accuracy'),\n",
              " ('exploratory', 'data'),\n",
              " ('data', 'cleaning,'),\n",
              " ('raspberry', 'pi'),\n",
              " ('neural', 'networks'),\n",
              " ('language', 'processing'),\n",
              " ('successfully', 'achieved'),\n",
              " ('decision', 'tree,'),\n",
              " ('see', \"project'\"),\n",
              " ('algorithms', 'technologies'),\n",
              " ('time', 'series')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r1WHkitdAdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "af43b84f-49b8-4ec7-ccfa-a1913aef2a12"
      },
      "source": [
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "\n",
        "import itertools\n",
        "words = list(itertools.chain.from_iterable(tokenized_doc))\n",
        "\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "bcf = BigramCollocationFinder.from_words(words)\n",
        "\n",
        "#filter_stops = lambda w: len(w) < 3 or w in new_stopwords_list\n",
        "filter_stops = lambda w: w in stop_words\n",
        "bcf.apply_word_filter(filter_stops)\n",
        "\n",
        "bcf.nbest(BigramAssocMeasures.likelihood_ratio, 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('machine', 'learning'),\n",
              " ('deep', 'learning'),\n",
              " ('neural', 'network'),\n",
              " ('convolutional', 'neural'),\n",
              " ('computer', 'vision'),\n",
              " ('natural', 'language'),\n",
              " ('jupyter', 'notebook,'),\n",
              " ('logistic', 'regression,'),\n",
              " ('technologies', 'used:'),\n",
              " ('random', 'forest,'),\n",
              " ('colab,', 'matplotlib,'),\n",
              " ('matplotlib,', 'seaborn.'),\n",
              " ('python,', 'jupyter'),\n",
              " ('google', 'colab,'),\n",
              " ('seaborn.', 'successfully'),\n",
              " ('notebook,', 'google'),\n",
              " ('state', 'art'),\n",
              " ('data', 'set'),\n",
              " ('random', 'forest'),\n",
              " ('achieved', 'accuracy'),\n",
              " ('exploratory', 'data'),\n",
              " ('data', 'cleaning,'),\n",
              " ('raspberry', 'pi'),\n",
              " ('neural', 'networks'),\n",
              " ('language', 'processing'),\n",
              " ('successfully', 'achieved'),\n",
              " ('decision', 'tree,'),\n",
              " ('see', \"project'\"),\n",
              " ('algorithms', 'technologies'),\n",
              " ('time', 'series')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m34t7lYPdTPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "2702a5e9-c7e7-4b04-d493-31002aaf690f"
      },
      "source": [
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "tcf = TrigramCollocationFinder.from_words(words)\n",
        "tcf.apply_word_filter(filter_stops)\n",
        "tcf.apply_freq_filter(3)\n",
        "tcf.nbest(TrigramAssocMeasures.likelihood_ratio, 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('convolutional', 'neural', 'network'),\n",
              " ('recurrent', 'neural', 'network'),\n",
              " ('deep', 'neural', 'network'),\n",
              " ('convolution', 'neural', 'network'),\n",
              " ('neural', 'network', 'image'),\n",
              " ('neural', 'network', 'model'),\n",
              " ('deep', 'learning', 'model'),\n",
              " ('art', 'deep', 'learning'),\n",
              " ('image', 'deep', 'learning'),\n",
              " ('tree', 'random', 'forest'),\n",
              " ('random', 'forest', 'classifier'),\n",
              " ('regression', 'random', 'forest'),\n",
              " ('colab', 'matplotlib', 'seaborn'),\n",
              " ('model', 'logistic', 'regression'),\n",
              " ('jupyter', 'notebook', 'google'),\n",
              " ('technology', 'logistic', 'regression'),\n",
              " ('natural', 'language', 'processing'),\n",
              " ('logistic', 'regression', 'random'),\n",
              " ('python', 'jupyter', 'notebook'),\n",
              " ('logistic', 'regression', 'model'),\n",
              " ('google', 'colab', 'matplotlib'),\n",
              " ('notebook', 'google', 'colab'),\n",
              " ('machine', 'learning', 'algorithm'),\n",
              " ('machine', 'learning', 'model'),\n",
              " ('machine', 'learning', 'technique'),\n",
              " ('decision', 'tree', 'random'),\n",
              " ('matplotlib', 'seaborn', 'accuracy'),\n",
              " ('exploratory', 'data', 'analysis'),\n",
              " ('image', 'convolutional', 'neural'),\n",
              " ('multinomial', 'naive', 'bay')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHc-nvIxdYYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ngrams = [('neural', 'network'),\n",
        " ('deep', 'learning'),\n",
        " ('random', 'forest'),\n",
        " ('logistic', 'regression'),\n",
        " ('machine', 'learning'),\n",
        " ('real', 'time'),\n",
        " ('jupyter', 'notebook'),\n",
        " ('decision', 'tree'),\n",
        " ('computer', 'vision'),\n",
        " ('raspberry', 'pi'),\n",
        " ('tf', 'idf'),\n",
        " ('google', 'colab'),\n",
        " ('pre', 'train'),\n",
        " ('state', 'art'),\n",
        " ('x', 'ray'),\n",
        " ('data', 'cleaning'),\n",
        " ('breast', 'cancer'),\n",
        " ('time', 'series'),\n",
        " ('credit', 'card'),\n",
        " ('convolutional', 'neural', 'network'),\n",
        " ('recurrent', 'neural', 'network'),\n",
        " ('deep', 'neural', 'network'),\n",
        " ('convolution', 'neural', 'network'),\n",
        " (\"sentiment\",\"analysis\"), \n",
        " ('time', 'series'),\n",
        " ('f', 'score'),\n",
        " ('object', 'detection')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_UWgocHeUXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "5f430262-b053-4ec3-feab-af027bd57067"
      },
      "source": [
        "#jalaj\n",
        "from nltk.tokenize import MWETokenizer\n",
        "tokenizer = MWETokenizer(ngrams)\n",
        "#tokenizer.add_mwe('a', 'study', 'to')\n",
        "\n",
        "\n",
        "\n",
        "# # de-tokenization\n",
        "# detokenized_doc = []\n",
        "# for i in range(len(data['project description'])):\n",
        "#     t = ' '.join(tokenized_doc[i])\n",
        "#     detokenized_doc.append(t)\n",
        "    \n",
        "dfObj = pd.DataFrame(columns=['project'])\n",
        "dfObj[\"project\"] = cleaned_documents\n",
        "\n",
        "tokenized_doc = dfObj[\"project\"].apply(lambda x: tokenizer.tokenize(x.split()))\n",
        "# de-tokenization\n",
        "detokenized_doc = []\n",
        "for i in range(len(dfObj['project'])):\n",
        "    t = ' '.join(tokenized_doc[i])\n",
        "    detokenized_doc.append(t)\n",
        "    \n",
        "\n",
        "dfObj['project'] = detokenized_doc\n",
        "\n",
        "dfObj"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>project</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de duplication task two major challenge de dup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>study forge companys performance comparison pe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>high psnr paperforthe result algorithm reconst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>accuracy problem video classification basis po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>aim side project simple user interface experie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>real_time data correction factor friss formula...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>team recommendation engine text analysis prof ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>open cv video analytics accident recognition i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>python retro text version classic game show wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>youtube sentiment_analysis video view behaviou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>629 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               project\n",
              "0    de duplication task two major challenge de dup...\n",
              "1    study forge companys performance comparison pe...\n",
              "2    high psnr paperforthe result algorithm reconst...\n",
              "3    accuracy problem video classification basis po...\n",
              "4    aim side project simple user interface experie...\n",
              "..                                                 ...\n",
              "624  real_time data correction factor friss formula...\n",
              "625  team recommendation engine text analysis prof ...\n",
              "626  open cv video analytics accident recognition i...\n",
              "627  python retro text version classic game show wh...\n",
              "628  youtube sentiment_analysis video view behaviou...\n",
              "\n",
              "[629 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY2gqRJYe90D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfObj.to_csv(\"data_preprocessed_final.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI_KORVqs6R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rET15T2ODJUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0DIn3C2DJz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "635c93c8-239e-498a-fa30-e7c968d06ee5"
      },
      "source": [
        "cleaned_documents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' de duplication task two major challenge de dup algorithm complexity time answer number record problem sort neighborhood approach second important challenge tradeoff precision recall for score problem machine learning technique training data',\n",
              " ' study forge companys performance comparison peer fundamental analysis financial statement relevant financial ratio companys status calculate liquidity financing performance ratio best performer sector bharat forge limited',\n",
              " ' high psnr paperforthe result algorithm reconstruction k space  superresolution image mri process highly sub sample knee mri data forthe result imaginary real part fourier space real value',\n",
              " ' accuracy  problem video classification basis position camera flowneta optical flow two video frame optical flow motion use resnet classification',\n",
              " ' aim side project simple user interface experience scalable responsive product aim use case job seeker hisher resume list relevant job input scalable web crawler job description various website job description resume text mining technique important information predictive model job',\n",
              " ' american sign language primary language north america deaf individual individualsthis language sign hand facial gesture bodily pasture image hand gesture alphabetic letter convolutional neural network image asl lettersafter loading data  network performance',\n",
              " ' customer level data lead telecom firm predictive model customer high risk churn main indicator churn high value customer revenue  telecom firm churn customer service usage build model customer  high risk strong indicator churn',\n",
              " ' million financial record fraudulent record task hand audit analytics platform data different erp base feature extraction engine rule client predictive model feature',\n",
              " ' algorithm dynamic maze obstacle video path source destination',\n",
              " ' author python library einsteinpy library computation general relativity geodesic equation ode visualisation part google summer code openastronomy umbrella standalone organisation esa socis cicd test automation documentation forthe project codebase research university toronto cern negative matter effect gravitational lensing project python software foundation numfocus esa',\n",
              " ' baseline f score credibility prediction event user credbank data initial exploratory data analysis multi level hierarchical attention network word tweet event level plan hierarchical transformer encoder decoder architecture model performance',\n",
              " ' end pipeline various abnormality chest x ray single model chexpert large chest x ray competition httpsstanfordmlgroupgithubiocompetitionschexpert stanford dataset chest x ray image multiple image processing data balancing adaptive histogram equalization various augmentation technique classification densenet architecture accuracy disease ensemble model',\n",
              " ' clustering model country socio economichealth factor country focus data  model outlier use silhouette score elbow method optimal number cluster different country cluster id  logical group pattern',\n",
              " ' team autonomous humanoid agent soccer simulate environment physic rule soccer optimize low level skill factor first ever simspark base humanoid gym openai environment rl algorithm trpo ddpg low level skill develop passing dodging defense positioning module voronoi point map ping hungarian algorithm active attacker selection secure nd position goalie skill scientific challenge league undergraduate team competition',\n",
              " ' client entity large number document number document document size task lot time task name entity recognition entity disambiguation technique',\n",
              " ' client many erp sap oracle financial financial data different erp data capture analysis requirement client audit analytics platform data single data model user exploratory data analysis visualization build analytics tool anomaly detection duplication top data model project data model script data erp etl script data new data model business problem interactive data exploration visualization template feature engineering training anomaly detection algorithm',\n",
              " ' common email address many team cause delay email wrong team person   sophisticated text mining pipeline python rapidminer easticnet adaboost algorithm tfidf partial pca feature engineering much better accuracy',\n",
              " ' credit risk model validation engagement bank engagement data preparation stage model validation stage data preparation step creation data requirement list co ordination client require data data quality check correctness data model validation stage implementation different model validation technique',\n",
              " ' dataset record different review restaurant data cleaning data visualization model sentiment restaurant review algorithm technology multinomial naive baye python jupyter notebook google colab matplotlib seaborn accuracy  end web app github link httpstinyurlcomrestaurant review sentiment',\n",
              " ' dataset record different top headline date data cleaning data visualization model stock price news headline algorithm technology logistic regression random forest multinomial naive bay python jupyter notebook google colab matplotlib seaborn accuracy ',\n",
              " ' dataset record different sm message data cleaning data visualization model sms spam ham algorithm technology multinomial naive bay python jupyter notebook google colab matplotlib seaborn accuracy  end web app github link',\n",
              " ' dataset record news headline data cleaning data visualization model news algorithm technology logistic regression multinomial naive bay python jupyter notebook google colab matplotlib seaborn accuracy ',\n",
              " ' dataset record movie script script word genre data cleaning data visualization model genre movie word script algorithm technology multinomial naive bay python jupyter notebook google colab matplotlib seaborn accuracy  end web app github link httpstinyurlcommovie genre classifier',\n",
              " ' dataset record independent feature exploratory data analysis data cleaning data visualization various model person diabete algorithm technology logistic regression svm decision tree random forest python jupyter notebook google colab matplotlib seaborn accuracy  end web app github link httpsbitlydttz',\n",
              " ' dataset record independent feature gender age annual income k spend score data cleaning data visualization model mall customer algorithm technology kmeans python jupyter notebook google colab matplotlib seaborn customer different cluster',\n",
              " ' dataset record independent feature age sex cp trestbp chol thal exploratory data analysis data cleaning data visualization various model person heart disease algorithm technology kneighbor decision tree random forest python jupyter notebook google colab matplotlib seaborn accuracy ',\n",
              " ' dataset record independent feature exploratory data analysis data cleaning various model chance student ucla algorithm technology linear regression lasso svr decision tree random forest k neighbor python jupyter notebook google colab matplotlib accuracy ',\n",
              " ' dataset web scrapping data glassdoorcom record unique feature job title salary estimate job description rating company name location exploratory data analysis data cleaning data visualization feature engineering various model data scientist salary algorithm technology linear regression decision tree random forest adaboost python jupyter notebook google colab matplotlib seaborn accuracy ',\n",
              " ' software air collaborative robot position aeroplane crack corrosion inspection body aeroplane train model predefin image crack corrosion lidar air cobot aircraft inspection live data image processing opencv image labelme software detection',\n",
              " ' shooting game pygame high end animation goal score enemy spaceship asteroid',\n",
              " ' bidirectional autoencoder base model information context reference knowledge softmax possible answer question edge base relation commonsense corpora conceptnet nell commonsense inclusive word vector relation conceptnet numberbatch research area natural language processing machine learning',\n",
              " ' cbir system inria holiday dataset colour histogram image descriptor feature image image dataset image descriptor csv file similarity image top result query image deep neural network feature better content understanding image composition',\n",
              " ' algorithmic model piotroskis f score trading strategy indian market period compound annual growth rate cagr  implement accrual earning anomaly trading strategy indian scenario cagr  back testing momentum trading strategy indian market period annual return use prowessiq prowessdx cmy database performance strategy python',\n",
              " ' scrape module disease related information web media newspaper last year unsupervised classifier sentiment analyser article type effect reader temporal regional analysis data progress modification hiv eradication campaign',\n",
              " ' high value player elaborate manual workflow player skill skill evaluation low value player multi million dollar problem industry low skill player four time revenue high skill player skill level player entire game help camera iot device cloud gpus fr cn and step game building player valuation fraud detection model',\n",
              " ' heavy load server ipf file system model red zone city',\n",
              " ' maximum entropy model koe implement baseline method chunk tag speech',\n",
              " ' pun syntactic characteristic corpus base metricsuwaterloo bert task state art result for score current sota',\n",
              " ' large team data analyst thousand data point various source project task advance natural language processing technique segmentation classification association technique information past data analyst training model accuracy',\n",
              " ' various machine learning technique real life scenario uci repository data various regression algorithm dimensionality reduction technique multidimensional real time data readmission diabete patient classification algorithm logistic regression random forest classifier',\n",
              " ' model mape day forward prediction interval novel attention base multivariate time series model id fan false negative false positive test sample model month run simulation control loop trip logic equipment understudy false alarm program crore annual savings deployment module term shutdown avoidance',\n",
              " ' exist work network embedding network structure user generate content better joint network representation project social network node latent low dimensional space mind follow property embedding structure network embedding account user generate content attribute node learn node representation scale free property network',\n",
              " ' muliple contact channel dialler email custome  challenge cost minimal impact money customer multiple algorithm clustering collaborative filtering sequence mining goal billion event payment data big data tool spark hive be python',\n",
              " ' lead contributor python library poliastro astrodynamics python problem orbit propagation solution lambert problem conversion position velocity vector classical orbital element orbit plotting interplanetary application important contribution api design plot module addition frame reference multiple bug fix talk poliastro pycon india poliastro linux window bot automation support issue wrapper astroquery neos data dastcom query module nasa sponsor sbpy project',\n",
              " ' analysis naphtha cracking process data haldia petrochemical dimensionality reduction pca digital analog naphtha cracking processand installation new monitoring sensor better data collection black box model naphtha cracking process component input feed furnace temperature fuel usage percent accurate ensemble model gradient tree regressor output variable',\n",
              " ' preprocessing ct scan image lung noise removal median filter gaussian filter gamma correction contrast enhancement k mean algorithm denoise image segmentation state art deep learning architecture u net kaggle lung cancer dataset dice coefficient metric accuracy segmentation',\n",
              " ' novel approach emotion textual conversation tree lstm deep learning model variation tree lstm behavior negative positive lexicon naive bay algorithm implementation noisy text insight data',\n",
              " ' propose novel method gans dialogue system sub problem capability variational encoder variation cvae semantic reproduce result recent state art model dialogue generation incorporate dialog act dialogwae behavior',\n",
              " ' semi supervise graph base approach link prediction derivational noun english web scraping algorithm derivational noun wiktionary dataset edge weight morphological semantic similarity noun gcn graph base semi supervise method link prediction two word',\n",
              " ' problem learn representation knowledge graph missing link propose improvement recent model distmult transe convkb tucker incorporation adjacent neighbor loss representation entity relation slight improvement state art mean reciprocal rank mrr hit hit benchmark dataset fbk wnrr',\n",
              " ' aim project deep neural network scratch classification task give dataset multi class classification case accuracy three scheme three scheme accuracy range percent logistic regression model dataset multi class classification case mention scheme accuracy scheme',\n",
              " ' aim project give dataset truncate svd different value dimension correspond reconstruction error data reconstruct space accuracy test set',\n",
              " ' retailer customer coupon  marketing strategy technique accurate model data different source ',\n",
              " ' naive bay tf idf vectorizer pipelinebecause large dataset news article accuracy improve accuracy regularization hyperparameter tuning',\n",
              " ' stanford word segmenter chinese segmentation simple edit distance erroneous word word vocabulary word minimum edit distance correction',\n",
              " ' available dataset covid kaggle pneumonia normal image data augmentation data data',\n",
              " ' figshare kaggle dataset classification various data augmentation technique new x ray image new cnn model scratch classification heatmap visualization validation heatmap help doctor comparison cnn model technique glcm svm pca',\n",
              " ' indiana university columbia asia chest x ray report model dbscan similarity sentence bert paper implementation report image captioning model report image report',\n",
              " ' multiple module deep learning network cn and rnn gru lstm multiple assignment deep learn network model multi class natural image classification data cifar',\n",
              " ' development deep learning base workload prediction model factory worker basis mental fatigue workplace safety multiple statistical test anova manova order data ann model accuracy  model logistic regression random forest classifier',\n",
              " ' reason wastage water farm  develop model total cost total return different type crop role modern machine output crop neural network weightage amount water final produce help simple regression technique exist data better visualisation website',\n",
              " ' accuracy parameter keras',\n",
              " ' conversational bot chatbot rasa framework zomato api call slack main purpose bot good restaurant discovery experience several indian city',\n",
              " ' web base application better handling waste disposal waste recycling distribution information sensor dustbin  infor mation cloud iot use clustering base algorithm genetic algorithm fuzzy logic optimal path waste collection center waste fill dustbin priority distance fuzzy logic efficient path cost distribution recycle material',\n",
              " ' android app drive practice user data smart phone sensor accelerometer gps gyroscope harsh driving practice k mean clustering algorithm threshold event sudden brake sudden acceleration sudden leave turn sudden right turn threshold separate automata event automata event detection real time basis accuracy android studio java',\n",
              " ' english french translator multi layer bidirectional dynamic lstm network word embedding training bleu score',\n",
              " ' give genetic variationsmutation evidence text base clinical literature  two data file one information genetic mutation clinical evidence text human expertspathologist genetic mutation',\n",
              " ' kangri language dataset fasttext model kangri language dataset embedding tensorboard tsne',\n",
              " ' psuedo random number generator spread code binary data decoding circuit encode data basis code verilog',\n",
              " ' robot person online convolutional neural network real time tracker challenging situation occlusion appearance change change opencv algorithm',\n",
              " ' autonomous electric rc car hostel corridor behavioral cloning concept convolutional neural network speed steering angle car project designing car control system hyper parameter tuning',\n",
              " ' model purchase amount various product personalize offer customer random forest regressor decision tree classifier combine feature customer demographic age gender marital status city type product detail product category history',\n",
              " ' model number people live cctv feed model self collect annotate data bus web interface user vacancy location bus real time cctv footage',\n",
              " ' user base management system one data user user webpage',\n",
              " ' real time lcd display implement memory variable virtual arm processor board employ appropriate notifier overflow attempt unallocated variable interrupt',\n",
              " ' feature sale big mart store we technique dataset distribution relevance variable model linear regression technique product wise store wise sale year',\n",
              " ' identification handwritten digit svm standard backpropagation neural net accuracy mnist dataset probability somebody financial distress next two year certain parameter unsupervise clustering mnist dataset median labelling supervise dataset number cluster model',\n",
              " ' densenet kera use data augmentation transfer train model low scale image epoch accuracy total epoch',\n",
              " ' retinanet model full fledge object detector backbone feature pyramid network train model focal loss smooth l loss pascal voc dataset',\n",
              " ' implementation dialogue state tracking paper fully statistical neural belief tracking nikola mrki reference implementation end knowledge carryover multi turn speak language understanding chen proceedings interspeech past utterance account intent slot state conversational agent github link base line different method performance speak language part conversational agent domain food ordering domain',\n",
              " ' multi density stream data clustering algorithm technology java eclipse ide apache maven  onlineoffline algorithm four main component online phase  summary information evolve multi density data stream form core mini cluster offline phase final cluster adapt density base clustering algorithm grid base method outlier buffer noise multi density data merge time clustering algorithm various synthetic real world dataset different quality metric scalability result experimental result algorithm study clustering quality multi density environment',\n",
              " ' solution multi class text classification problem variant convolution neural cnn rnn solution feature extraction text word embedding technique wordvec technique google tensorflow python numpy anaconda jupyter notebook understanding intricacy architecture neural network impact various parameter',\n",
              " ' implement neural network classification network regularization dropout technique standard neural network architecture tensorflow framework scratch parameter optimization analyse different embedding technique various downstream task natural language processing credit card default prediction model financial firm sensitivity specificity statistical parameter movie recommendation system collaborative content filtering top feature vector',\n",
              " ' project  classification model object image first generation deep residual network pre train cnn model whole slide image video transfer learning technique purpose brand inappropriate contentad nudity',\n",
              " ' netflix lot anonymous rating data prediction accuracy bar  cine match training data set objective project rating user movie  difference predict actual rating rmse mape',\n",
              " ' objective new kernel desire system call language c core functionality kernel website research papers',\n",
              " ' objective real life problem simple technology remote control various micro controller electronic component',\n",
              " ' football goal cristiano ronaldo goal number model better accuracy decision tree random forest logistic regression z data science challenge',\n",
              " ' parallelize version mudi stream algorithm multi density clustering algorithm challenge generate processing streaming data multi density cluster logic algorithm distribute environment efficient manner technology eclipse ide propose solution synthetic non synthetic data set various size result  serial implementation algorithm',\n",
              " ' quantify similarity set dna string star heuristic search implement quoridor player minimax search alpha beta pruning support variable board dimension learn parameter bayesian network know case disease symptom disease learn parameter',\n",
              " ' top team test accuracy challenge model toxicity unintended bias respect minority highly imbalanced dataset negative target successfully reduce bias imbalance data sample weight various custom loss function bcewithlogitsloss tune multiple bert transformer various deep learning architecture pytorch framework various ensemble technique accuracy test metric',\n",
              " ' human behavior robot speech text conversion object detection recognition intent entity detection rasa audio environment iot system docker online offline mode',\n",
              " ' review exist technique analysis natural texture extraction feature classification texture image classification natural image rock texture signal processing pattern classification technique performance metric false positive rate false negative rate tags knn machine learning supervise learning texture classification',\n",
              " ' simple processor basic program vhdl bit instruction set implement pipeline datapath data forwarding bit branch predictor streamline execution',\n",
              " ' software fault prediction various advanced ml dm technique challenge heavily imbalanced data set curse high dimensionality non availability standard framework technique consideration consideration nasa repository technology be be notebook',\n",
              " ' stock price different company underlying financial asset detail exploratory data analysis data different company create cluster company different sector tsclust create prediction forecast underlying financial asset achieve th position online round second round team',\n",
              " ' physical force inferential feature presenceabsence certain force devise calculus base technique distinguishing trait dewet graph modelling automatic model selection wrapper different algorithm cross validation score pipeline approach pca svm accuracy ',\n",
              " ' major part computer system malware attack give piece filesoftware malware project  file nine class  multi class classification problem',\n",
              " ' project model human activity walkingupstairs walkingdownstairs lay data set subject data set different activity smartphone waist data help sensor accelerometer gyroscope smartphone experiment video data',\n",
              " ' virtual keyboard use brainsense sensor facility suggestion box ',\n",
              " '  many people park particular day environmental information data long period time various park country missing value imputation knn feature engineering select variable final model svmradial xgboost',\n",
              " ' project ambulance provision system smart city trip time  real city map openstreetmap platform simulation urban mobilitysumo simulation model define require traffic element traffic light vehicle lane detector road priority map netedit',\n",
              " ' image generation text art thorough literature survey propose model task',\n",
              " ' offensive language identification automatic categorization offense type offense target identification attention layer hierarchical attention network han accuracy art elmo bert flair stack embedding glove fasttext',\n",
              " ' different kind data different type architecture technique pre train word embedding one hot vector representation training rnns normal nn validation accuracy  k sample every dataset',\n",
              " ' terrain spy bot vr field view integrate computer vision various feature',\n",
              " ' drone place place gps  camera facial recognition',\n",
              " ' crop hydroponic implement deeplearning outcome computer vision good bad crop',\n",
              " ' human emotion dynamic facial expression real time pre train weight imagenet weight initializer faster convergence random initialization class imbalance loss weighting regularization oversampling rare class different matric ie precision recall for score auprc auroc',\n",
              " ' exploratory data analysis customer demographic behaviour model purchase amount customer various product company personalise offer customer different product ensemble technique final model decision tree xgboost th position leaderboard analytics vidhya',\n",
              " ' generative adversarial net gans computer vision image nlp task language gan setup help curriculum learning teacher variable length learning google billion word corpus generate sequence  test set model sequence length',\n",
              " ' give dataset synthetic image object different pose lighting condition cluttered random background task fly furniture respective class class k training example class label heavy imbalance inception resnet v model fine tune initial layer last fc layer transfer learning good test accuracy  tf slim module different metric precision recall auprc for score',\n",
              " ' implement statistical regression technique hypothesis testing probabilistic distribution assumption homoskedasticity normality consistency parameter model hypothesis test jarque bera breusch pagan white test closely fit model',\n",
              " ' dark channel implement guide filter transmission map edge preserve effect',\n",
              " ' implement stochastic first order discrete hidden markov model stock price movement company implement various algorithm hmm baum welch they hill climbing algorithm unknown parameter forward backward algorithm probable state future stock price movement near future price movement sbi common stock accuracy year',\n",
              " ' home automation project nodemcu integrate google assistant ifttt add various security protocol',\n",
              " ' institute challenge grant student innovation scheme sgsis sponsor research industrial consultancy sric cell iit kharagpur student innovation project value rs lakh maximum period year prototype development printer low cost maximum efficiency house minimum manual interference',\n",
              " ' objective price house explanatory variable aspect house exploratory data analysis data cleaning outlier detection missing value base model random forest regressor regressor xgboost linear regressor',\n",
              " ' advisor prof sudip misra real time election management software feature event scheduler otp verification chat box interactive profile option software engineering concept srs documentation uml case diagram state diagram sequence diagram class diagram',\n",
              " ' professor pawan goyal hypernym hyponym relation word pair network manual feature vector word general word average degree context number neighbor context context specific word subset general word degree entropy network different classifier best result',\n",
              " ' lung cancer detection art yolo use yolo algorithm data segmentation ct scan image lung pre train model large medical image dataset transfer learning',\n",
              " ' uffc real time streaming video remote control robot vr format android application robot mobile application uffc finalist project e yantra e yantra idea competition iit bombay uffc anveshan',\n",
              " ' project data glove flexor bend sensor accelerometer arduino nano bluetooth module gesture user hand intel galileo gen microcontroller several wirelessly connect peripheral device uffc system user device network gesture uffc project intel innovation festival internet thing rapid prototyping camp top project',\n",
              " ' gesture operate robotic vehicle locomotion orientation operator hand change orientation accelerometer ic analog data digital data avr microcontroller motor microcontroller motor driver ic',\n",
              " ' online airline reservation system prof g sivakumar iitb missionary cannibal salesman problem implementation simulate annealing genetic algorithm guide prof pushpak bhattacharyya iitb application establish machine learning technique cmu pronunciation dictionary text phonology conversion guide prof pushpak bhattacharyya iitb warmr bet framework guide prof g ramakrishnan iitb alpha expansion partial labeling undirected graphical model guide prof sarawagi iitb apr',\n",
              " ' simple gui live video stream detect face frame viola jones algorithm track mark face stream',\n",
              " ' portable body simple computer vision technique gesture detection require gesture image frame new directory memory interface processing storage device capture image',\n",
              " ' first image compression linear algebra technique compress image class input image image processing technique python opencv framework',\n",
              " ' cloud base application interaction doctor patient indexing method privacy keyword cloud phone number secret key',\n",
              " ' command line matrix calculator interpreter python class function c library ',\n",
              " ' complete compiler cool language phase namely lexer parser semantic analyzer code generator project part coursework iit hyderabad course principle compiler design fifth semester',\n",
              " ' decentralise system robot synchronise choreograph move message passing agent move runtime robot',\n",
              " ' distribute database project front end patient record fragment table record state use sqlplus oracle db php javascript with css',\n",
              " ' feedback portal feedback student aggregate analysis collect feedback data analytics natural language processing technique sentiment analysis topical modelsthe project institute sense receive feedback',\n",
              " ' glove  different mouse keyboard operation hand gesture  window base application arduino uno five flex sensor glove coding c c project second position annual electronics exhibition niit university silicon de art',\n",
              " ' gpu accelerate implementation extreme learning machine python theano scipy stack extreme learning machine black box model classification regression task',\n",
              " ' hack hill project  face recognition gate entry problem college cnn architecture face recognition',\n",
              " ' library management system semester project detail availability book service student language c',\n",
              " ' machine learning model champion epl  svm winner fixture epl winner',\n",
              " ' modify rnn model memory module attention mechanism important part question answer custom build dataset hindi newspaper',\n",
              " ' neural network one language project  sequence sequence model dataset english french sentence new sentence english french dataset small portion wmt french english corpus project part deep learn nanodegree foundation course udacity',\n",
              " ' program python use identification tree microsoft cognitive service emotion detection api various factor age gender current state mind travel location  chennai',\n",
              " ' project prediction task loan eligibility process customer use logistic regression decision tree performance',\n",
              " ' pytorch implementation neural algorithm artistic style l gatys ecker bethge httpsarxivorgab',\n",
              " ' quadcopter flight control system arduino uno mpu   windy condition auto level  pitch roll controls transmitter  quadcopter scratch arduino c',\n",
              " ' real time eye gaze tracking project image processing center eye center circle gui',\n",
              " ' real time application traffic signal duration intersection image processing amount traffic direction',\n",
              " ' research microeconomic macroeconomic factor personal credit history could afftect morgage risk machine learning technique concept pca dimension reduction upsampling skewness dataset data python pandas sklearn jupyter',\n",
              " ' simple naive attempt creation voice command drive system user interface c speech command small set function executable file system fun interactive functionality first jab speech recognition also first award winner project prize nd runner innoprakalp college technical fest kiet',\n",
              " ' solution decentralize banking system be drive decentralize credit rating agency shortcoming traditional cra tool python keras javascript solidity kovan ethereum testnet oracalize lightgbm',\n",
              " ' system people mask  resnet architecture convnet pytorch opencv',\n",
              " ' utility ro application python estimation laser scanner input data state turtlebot v binary occupancy grid order obstacle obstacle correction robot state angular linear component velocity',\n",
              " ' vending machine patient deep learning various detection flask iot',\n",
              " ' way mother home early stage neonatal jaundice order early treatment newborn mortalitymorbidity raspberry pi setup baby face image jaundice face skin color facial feature',\n",
              " ' web portal effective mobilization youth rural area  training progress post placement',\n",
              " ' web project user disease basis symptom api develop web application',\n",
              " ' website photography skill interested photographer website html css basic javascript code website four contributor photograph  server side part website user request feedback laptop desktop better experience',\n",
              " ' work modelprototype effective utilization whooshing air high speed train wind energy horizontal wind turbine bridge railway track elecrama mumbai',\n",
              " ' ability direction stockindex price market dealer investor profit data mining technique high forecasting accuracy stock price movement project  various data mining technique price movement nifty index indian stock market approach logistic regression k nearest neighbor classification nave bay random forest neural networksub vector machine svm experimental result svm superior predictive performance model',\n",
              " ' high time resolution universe survey pulsar fast transient parkes telescope majority pulsar detection false positive radio frequency interference noise various machine learning algorithm feature importance performance different approach binary classifier real pulsar candidate problem class imbalance high geometric mean accuracy',\n",
              " ' academic oriented project deep learning encoder decoder model two component cn and input image set feature rnn feature rich descriptive language',\n",
              " ' roc auc score top challenge leaderboard lstm gru base model comment six type toxicity',\n",
              " ' advance deep learning variant dominant architecture many nlp task question answer qa well research problem classical problem natural language processing system question way human project  first quick baseline model nearest neighbor algorithm bag word technique usage nearest synonym help wordnet pre train wordvec model wordvec model we closest word dictionary synonym wordnet we base line model  sequence deep learning shortcoming bag word technique',\n",
              " ' be system creation attack play system run contrast fix preprogram play',\n",
              " ' patient day hospital tool python be sql technique ml algorithm random forest neural network imbalanced data random oversampling method cross validation',\n",
              " ' aim sentiment analysis various social media platform kellogg brand platform twitter google news blog youtube instagram various platform information link title content comment beautiful soap html parsing sentiment analysis  technique nlp word embedding tf idf twitter instagram analysis sentiment analysis factor location',\n",
              " ' aim sale forecasting travel agency mode value chaindiversity flight bus train hotel holiday package net amount fare exist user',\n",
              " ' classification problem patient diabete tool python technique machine learning model classification bagging',\n",
              " ' idc breast cancer histology image idc  tool classification image convolutional neural network ml',\n",
              " ' algorithm classifier e mail spam naive bay classifier python set email  email dataset bag word tf idf perceptron algorithm accuracy model  approx',\n",
              " ' algorithm classifier novel data point label large label set algorithm generalization error analysis depthreference local embedding extreme multi label classification k bhatia h jain p kar varma p jain',\n",
              " ' common thread operation supervise hybrid algorithm wsd supervise hybrid algorithm wsd detail common thread action comparative study supervise hybrid algorithm accuracy relative amount data algorithm word wsd supervise setting effective efficient contextual parameter hybrid algorithm wsd',\n",
              " ' algorithm low rank approximation give high dimensional matrixreference fast monte carlo algorithm low rank approximation frieze be kannan vempala',\n",
              " ' aim development ultra low cost robotic manipulator arm hand gesture arm functionality degree freedom higher degree grab mechanism project arduino platform communication dual point wireless link frequency',\n",
              " ' form microstrip antenna regular clothing development unobtrusive smart wearable system',\n",
              " ' airborne image severe weather condition turbid mediumhaze snow dust image contrast color fidelity main research work haze airborne image real time issue effective improve dark channel opencv c library order dehaze image real time  dcp algorithm parallel processing environment nvidia gpu kepler k platform parallel processing  cuda programming reduce computation time process dehaze image x speedup cpu computation',\n",
              " ' amazon review certain extent   question answer system feature comparable product  stanford nlp toolkit sentiment analysis statistical summary give product feature  novel rating mechanism  salient keyword feature product feature',\n",
              " ' android app common object smartphone camera real time app text speech number object class  human face attribute age gender emotion app text image tool use ssdmobilenetv cn and object detection microsoft cognitive api face attribute firebase ml kit ocr tensorflow lite converter object detection api android app',\n",
              " ' android app visually impaired people current location phone',\n",
              " ' android application location android smartphone middle ware server sm service data communication two mobile gpslocationlistener mobile coordinate request mobile sm sevice google map',\n",
              " ' android application recipe raw vegetable fruit smartphone camera real time app multiple object detection tracking list detect vegetable user preference recipe api recipe api user preference diet allergy cuisine mean average precision map  tool tiny yolo layer convolutional neural network object detection google colaboratory tensorflow darkflow training firebase user preference',\n",
              " ' android application nearby trash bin navigation map initiative swachh bharat abhiyaan govt india feature municipal corporation smarter garbage collection complaint registration user',\n",
              " ' application karaoke file audio processing audio speaker speech song property audio',\n",
              " ' application symptom input user disease  help artificial neural network model treatment precaution management measure predict disease help web crawler app doctorspatient precise disease treatment time help click',\n",
              " ' e commerce marketplace doctor hospital product three side application controls vendor administrator end user',\n",
              " ' effort optimize keyboard layout bigram probability travel time random numbersalgorithm use arrhenius equation probability annealing matlab program',\n",
              " ' encryption application system python principle enigma machine',\n",
              " ' object detection app flutter  tflite file flutter  yolo ssdmobilenet model app',\n",
              " ' buy patter and numerous retail transaction retailer sale customer behavior association rule',\n",
              " ' student performance dataset student performance various demographic social school related attribute predictive modelling',\n",
              " ' impact store price reduction number pid sale productidentify price threshold impactmodel methodology mix modeling data preparation modeling tool sas',\n",
              " ' titanic dataset kaggle  survival passenger',\n",
              " ' optimal feature record audio conversation marmoset new world monkey species center computational brain research ccbr technology mit supervise technique statistical model marmoset call accuracy  unsupervised approach language identification language marmoset speech system python average cluster purity  two stage agglomerative bottom clustering approach',\n",
              " ' gdps different indian state way ',\n",
              " ' anomaly detection classfication time series sensor data image deep learning time series image temporal pattern convolutional auto encoder variational auto encoder feature extraction neural network classification anomaly detection technique machine learning domain deep learning  better result horizontal cascading deep learning model',\n",
              " ' mathematical topological concept mobius stripthe mathematical equation mobius strip algorithm opengl model mobius strip analysis shortcoming model code algorithm strip model use openscad model strip stl format printing knowledge tessellation finite element analysis',\n",
              " '  product specification product  product sentiment review popular e commerce website',\n",
              " ' area nlp machine learningobjective review review rating review  scorerating rating review review approximate proxy way polarity positivitynegativity review',\n",
              " ' part internship lml mobile pvt ltdhyderabad data science intern application different churn prediction model logistic regression decision tree svm boosting ensemble method neural network comparison performance term accuracy stability simplicity scalability',\n",
              " ' part curriculum  automatic license plate recognition alpr system project  car number plate character detect plate purpose  ml algorithm  useful project area intelligent transportation system   parking area   raspberry pi model',\n",
              " ' part project data yahoo website alert case discrepancy technology java pig hadoop big data',\n",
              " ' part model basic yolo algorithm',\n",
              " ' shopper  dream product photo automatic product recognition product picture different lighting angle background level occlusion different fine grain category example ball chair egg chair furniture dutch oven french oven cookware todays general purpose recognition machine subtle difference photo difference decisionstackle issue conference computer vision pattern recognition cvpr workshop data scientist fine grained visual categorization part workshop cvpr google malong technology data science community state art automatic image classification competition fgvc workshop organizer malong technology  algorithm important step automatic product recognition category label furniture home goods image',\n",
              " ' aspnet mvc migration web application migration aspnet mvc architecture project new presentation layer service layer wrapper class library exist component business logic database layer wrapper class exist application exist architecture requirement aspnet mvc claim platform create wrapper class mvc application exist code base develop controller base various action filter mvc application prepare automated unit test case rhino mock common library method reusabilityinsurance financial incur tool different type claim auto home property worker compensation general liability division claim user interface loss detail role requirement user story user story estimation sprint plaining ui user payment note module json data handler jquery logic different scenario payment note automated unit test case rhino mock',\n",
              " ' assist modelling team right variable data  premature loan closure request non banking financial company',\n",
              " ' medical image processing laboratory iit kharagpur prof debdoot sheet dropout denoise autoencoder theano python medical image analysis',\n",
              " ' standard feature almost digital keyboard use language model core project  lstm base character level language model next character sequence input character code project python tensorflow',\n",
              " ' automatic generation movie scene dialogue conversation people lstm corpus improvement scene  conversation contexts penalty loss function generation context dialogue',\n",
              " ' automatic image colorization image significant interest several practical application area restoration aged degrade image project cyclegan grayscale image colorful rgb form',\n",
              " ' background word sense disambiguation wsd heart natural language processing problem wsd task computationally determine sense word contextaim dichotomy machine human way  sense meaning various parameter wsd also sense behavior sense annotator machine  level difficulty various class word sense pattern contextual clue annotation task intelligence suitable machine learning algorithm wsd right balance rule base statistical learning base approach step stone strong be base wsd system',\n",
              " ' past six month data modelling be programming churn rate come monthlogistic regression',\n",
              " ' baseline various task detection english hindi code mix corpora effect code borrowing classification task engineer feature basis code switch various deep learning model architecture bilstm cnns hans fully connect layer combination various type attention mechanism self attention multi head attention',\n",
              " ' event kshitij asias largest techno management fest semi autonomous robot wire pick drop object underneath',\n",
              " ' brain gene certain pattern certain change pattern gene various disease gan  false image brain gene training purpose',\n",
              " ' breast cancer common invasive cancer female   female cancer  invasive cancer woman  cancer death male female breast cancer mammography process low energy x ray human breast diagnostic screen tool goal mammography early detection breast cancer detection characteristic mass micro calcification mammogram less satisfactory experience pleasant unpleasant experience mammogram woman purpose study qualitative research method patient satisfaction mammography experiencethe project report mammogram experience study experience subject mammogram test knowledge symptom disease perceive benefit test family history disease knowledge testing home  machine disease',\n",
              " ' linux base operating system efficient mangement power good gui frontend c sharpthe idea linux os c c',\n",
              " ' model optimal mix marketing execution lowe brand canada',\n",
              " ' model trip fare customer  least two trip particular distance travel time',\n",
              " ' model deep learning cn and tha particular x ray image covid person',\n",
              " ' multiple linear regression model prediction car price factor pricing car current market business',\n",
              " ' predictive model customer  customer segment pyramid new customer consistent customer consistent customer best customer suitable campaignmodeling methodology logistic regression data preparation modeling tool sql sas',\n",
              " ' deep learning chatbot natural language processing deep learning different neural network system',\n",
              " ' multiple linear regression model car price american marketproject insignificant variable multicollinearity rfe ivf',\n",
              " ' multiplayer ping pong game fpga fpga verilog input vga port',\n",
              " ' pipeline real world user supply image image convolutional neural network image dog algorithm estimate canine image human face  resemble dog breed',\n",
              " ' recurrent neural network lstm cell  tv script season simpson network tv script',\n",
              " ' simple convolutional neural network image cifar dataset accuracy ',\n",
              " ' android application iit kharagpur  bus campus  estimate time arrival bus location bus location various bus stop  use google map api time route estimation firebase database',\n",
              " ' autonomous robot black line node colour shape object path raspberry pi camera black line colour shape node capture image',\n",
              " ' object detection module raspberry pi machine learning algorithm apply yolo ssd algorithm deep learning',\n",
              " ' build hospital management system aspect hospital patient information medicine third party insurance purpose main purpose design  application different technology',\n",
              " ' tetris game x lead matrix pcb arduino use different controller button joystick laptop processing sketch wireless',\n",
              " ' bus route prediction optimum route optimization peak hour clustering machine learn predictive clustering model',\n",
              " ' classification different type graphite flake image convolution neural network tensorflow',\n",
              " ' restaurant quality several feature cuisine description model xgb classifier python scikit learn library',\n",
              " ' classify different fashion apparel convolutional neural network apparel classification style dataset class alexnet model top average accuracy  accuracy  top accuracy  current baseline  caffe cuda support platform classification googlenet residual network performance',\n",
              " ' classifier scale version vggnet dress skirt jeans shirt pant',\n",
              " ' classifier scratch cn and train accuracy validation accuracy pre train vgg inception model validation accuracy  ',\n",
              " ' cancerous breast histology image convolutional neural network tensorflow dataset breast histology image size neural network python class complete tensorflow session file accuracy around',\n",
              " ' different quality video stream class imbalanced data distribution resnet architecture top exist pretrained vgg model feature extraction sequence video frame sequence vector rnn gated recurrent unit gru sequence frame respective class average auc value pipeline project user behavior real time alert various monitoring system',\n",
              " ' noise sentiment tweet much weightage context text preprocess data assorted technique bag word tf idf wordvec docvec apply classification model logistic regression random forest feature set fine tuning xgboost hyperparameters wordvec feature for score ',\n",
              " ' client truven health analyticsworking developer gather requirement ui processing logic store procedure raw data hospital logic various report normalize data',\n",
              " ' cloud computing information retrieval invert index apache spark python scratch apache spark cluster machine ubuntu setup apache spark distribute search query information size gb functional programming construct lambda expression',\n",
              " ' store various parameter parameter store revenue result  marketing strategy store various city',\n",
              " ' popular machine learning framework tensorflow dlj gensim several cloud platform aws google cloud ibm softlayer hetzner practical aspect hardware implementation quality repeatable benchmark docker container github link httpsgithubcommanneshivabenchmark wordvec framework httpsgithubcommanneshivabenchmark gpu platform link blog result httpsrare technologiescommachine learn hardware benchmark httpsrare technologiescommachine learn benchmark hardware provider gpu part',\n",
              " ' performance different model state art model bert squad dataset text generation sentiment analysis',\n",
              " ' final john hopkins healthcare design competition app prognosis skin disease classification common public',\n",
              " ' startup web base platform company profile companys profile review premium deal bonus use with css framework javascript ajax php mysql',\n",
              " ' image grey scale rgb simple procedure single grey scale image many plausible coloured image  auto encoder deep neural network task',\n",
              " ' cpu scheduling algorithm fcfs round robin java process  parallel analysis performance gui',\n",
              " ' basic compiler julia language c part compiler course  lexer scanner simple code statement',\n",
              " ' course hosting website coursera mongo database backend server angular j dynamic website nodej framework  self assessment assignment submission timetable planner',\n",
              " ' portal registration accommodation attendee college fest add functionality id generation room allotment various statistic technology lamp linux apache mysql php',\n",
              " ' python module data file data analysis radio astronomer data scientist actively maintain package care oifit data documentation ci writing unit test main responsibility',\n",
              " ' small prototype cycle part introduction engineering design course',\n",
              " ' visualization restaurant rating unsupervise supervise machine learning yelp academic dataset code request academic honesty policy eec dept',\n",
              " ' web application user record transaction withdrawal deposit current balance account php mysql main technology project',\n",
              " ' admission portal applicant detail admin applicant various criterion gui javafx back end java',\n",
              " ' arm simulator subset arm instruction c functionality arm instruction input encode hexadecimal format instruction  execution function phase fetch memory',\n",
              " ' interactive dashboard publicly available data hospital peer decision insight operational performance finance',\n",
              " ' app airway part airberlin hackathon advanced concept google map app flight experience large stable application short span time',\n",
              " ' app another app football lover prediction engine english premier league match concept java app neural network prediction multiple factor away factor head stat team value',\n",
              " ' exploratory analysis we census income data uci machine learning repository use be ibm spss weka dataset mine various pattern data set record various data pre processing technique value imputation outlier detection decision tree random forest knn tuple various performance measure apriori algorithm association rule mining data',\n",
              " ' data cleaning openstreet data map unstructured data mongod b prefrom analytics data',\n",
              " ' data source twitter proper sentiment analysis tweet lstm svm prediction',\n",
              " ' data data record feature data prduct image url product title main feature approach  text featurization tf idf wordvec image featurization one hybrid feature pairwise similarity concept  siamese network deep learning algorithm keyword deep learning text mining similarity matrix',\n",
              " ' deep learning approach extension fabric detection online shopping website tsne clustering vgg type encoder network encoding resnet classifier',\n",
              " ' demand forecasting key component every grow online business proper demand forecasting process place  right amount stock hand give time food delivery service lot perishable raw material  company daily weekly demand task demand next weeksweek centre meal combination historical data demand product centre task  catboost mean encoding lag base feature',\n",
              " ' computer vision base setup laboratory scale belt deviation depth fault rip conveyor belt image processing technique complete belt image color base segmentation laser beam depth rip belt peak detection laser beam weight mean surround pixel local maxima every column model belt deviation multi scale feature fusion network depth wise separable convolution weight loss function',\n",
              " ' mismatch frontend amplifier circuit bio medical data acquisition system simulate analyze output ecg signal soc cmo circuit testbenche orcad pspice',\n",
              " ' responsive dating website java jsps postgresql db feature  social networking site back end er diagram redundancy table sql query',\n",
              " ' udp base application multiple client computer networktechnology tool netbeans ide java',\n",
              " ' basic algorithm fact set document spread false news social media',\n",
              " ' model image class image dataset image generative adversarial network technique',\n",
              " ' review rank system amazon product review helpfulness user review current system user vote review ittools technology jupyter notebook spyder gui anaconda',\n",
              " ' secure system iot user smart phone lock vehicle qr code scanning rsa encryption algorithm location tracking technology android google map api php mysql javascript java',\n",
              " ' detailed exploratory analysis sas key marketing vehicle sale company cpg industrymultivariate linear regression model statistical technique major variable revenue companyanalyzed rois brand activity better return activitymodeling methodology multivariate regression data preparation modeling tool sas',\n",
              " ' anomaly time large scale event log manufacturing process  large scale hierarchical lstm model initial sign anomaly pattern long sub sequence different type anomaly sequence length problem exploration phase',\n",
              " ' face mask image deep learning model face image mask task pipeline two task  face imageframe face person mask aim project course face mask detector  pytorch lightning try  pytorch implementation certain task',\n",
              " ' detection vehicle video data set opencv python order model two wheeler four wheeler vehicle',\n",
              " ' user comment articleextract topic comment article lda various similarity measure',\n",
              " ' machine learning algorithm knowledge base baseline genetic variation',\n",
              " ' content base clustering model unstructured html document k mean algorithm pre processing data parsing beautiful soup nltk library python',\n",
              " ' continuous online monitoring system om power system stability phasor measurement pmu measurement generator bus art propose om information fault clearance  convolutional neural network heatmap representation measurement input instability prediction extensive simulation standard ieee ieee bus system effectiveness propose om  two method set critical generator unstable case',\n",
              " ' gui base application graph graph algorithm pyqt framework several graph algorithm maximum matching graph search shortest path visualization np algorithm minimum maximum dominant set maximum clique',\n",
              " ' kernel module keyboard macro proc file system modification kernel space gui editing macro create tkinter base gui macro possibility macro system',\n",
              " ' linux software operating system person eye minute dlib facial landmark detection module',\n",
              " ' machine learning method automatic social role identification user profile bio description significant increase performance best perform baseline deep learning ensemble model glove elmo word vector data stanford corenlp layer use bilstm dense time layer',\n",
              " ' machine learning model various emotion happiness sadness disgust surprise fear anger facial landmark detection vector machine technique',\n",
              " ' pulse oximeter sensor pulse rate person layer neural network person asleep awake state age group',\n",
              " ' song recommendation system item item collaborative filtering technique million song dataset precision recall evaluation google colaboratory',\n",
              " ' system classification image keras library cifar dataset image ten class airplane cat horse car',\n",
              " ' system image hidden part visually plausible way autoencoder base approach image reconstruction',\n",
              " ' visual question system deep neural network question image',\n",
              " ' website user image service object  service seefood detector coordinate label detect object tool django web framework development server pycharm ide development docker distribute cloud computing',\n",
              " ' window application music mood user  speech web app django sentiment nltk library top five idea',\n",
              " ' wordvec model semantic similarity text story dataset game throne',\n",
              " ' be bot ultimate tic tac toe game pruning technique game play',\n",
              " ' android app use ocr techniquesdeep learningmachine learning piece handwritten document standard document time new roman font',\n",
              " ' android base game application learn disability autism kid project dr vinod head neurology department aim kochi india',\n",
              " ' ann hand write digit mnist dataset test classification accuracy deep cn and lenet architecture tensorflow kera pytorch different batch size learn rate behavior loss function accuracy epoch different batch size learn rate sgd adam',\n",
              " ' application financial account official student welfare department various feature excel ease use enhance functionality various level access student official data excel sheet customize expense report technology lamp linux apache mysql php',\n",
              " ' interactive chat bot natural language processing technique planning meetup basic query',\n",
              " ' nlp classification model free text job description we bureau labor statistic standard occupation class solution wordvec vector embedding approach bl corpus gradient boost model classificationthe solution major financial service organization customer risk profiling major bottleneck risk profiling process classification customer occupation self fill job descriptionthe solution savings man day worth effort manual mapping bureau labor statistic standard occupation classification data',\n",
              " ' topic modeling algorithm latent dirichlet allocation gibbs sampling identification personality trait',\n",
              " ' part android nano degree xyz reader rss reader application android part project advanced concept android uiux depth material design android animation complex ui component',\n",
              " ' part android nano degree ubiquitous project watch app present weather temperature open weather map api image weather round squar type android watch project concept android wearable development',\n",
              " ' different model classification urgency non urgency voice message',\n",
              " ' end chatbot be component speech synthesis tts custom language tacotron waveglow architecture speech recognition we indian accent deepspeech architecture be natural question answer chatbot seqsqe lstm architecture be component unity vr space framework python c unity pytorch tensorflow restful api aws server',\n",
              " ' develop gram panchayat adoption advisor gram panchayat various factor education healthcare etctechnology nave bay sklearn pandas django numpy bootstrap',\n",
              " ' develop software freedom day website year software freedom worldwide celebration free open source software foss technology angularjs firebase html css grunt bower website open source platform github',\n",
              " ' interactive game inbuilt library python number',\n",
              " ' project use html css dating website smiley game guess game',\n",
              " ' develop text speech model indian non indian language tacotron wavenet deepvoice rnn seqseq encoder decoder architecture framework tensorflow nltk pytorch',\n",
              " ' infrastructure question chatbot admission enquiry vit universityvarious nlp technique tokenization pos tagging chunking ner tagging keyword extraction',\n",
              " ' develop voice cloning architecture multimedia company movie dialogue creation different different character architecture deepvoice tacotron sub model bi lstm',\n",
              " ' develop website handsforhelp website technology html css javascript collaboration platform github development',\n",
              " ' develop website sac student affair council smvdu website technology html css javascript collaboration platform github development',\n",
              " ' biometricfingerprint recognition technique issue security fingerprint system visual cryptography technique',\n",
              " ' chatbot engineering student  career choice ms mtech ias ies mba job',\n",
              " ' deep learning framework keras pytorch pytorch lot flexibility research  clear choice researcher everything lightning training loop validation loop gradient clipping checkpointing loading gpu training python library pypi',\n",
              " ' development computer vision algorithm single unidentified vehicle secure premise occlusion kalman filter assist occlusion handling motion  suspicious activity',\n",
              " ' missing link prediction multi view nodevec embedding network centrality measure machine learning classifier svm neural net',\n",
              " ' final year project field control engineering title project bifurcation analysis ofstatcom aim project behaviour statcom various operating condition mathematical representation statcom behaviour matlab',\n",
              " ' eduknow education portal application school parent app information school student stream video app student fee payment part project efficient push notification streaming video youtube rich interactive secure webview payment purpose volley library efficient networking',\n",
              " ' low resolution video high resolution video recurrent neural structure resnet alexnet',\n",
              " ' encryption tool test file lead encryption standard java gui',\n",
              " ' voice text text sentiment entity phrase language detection analysis translate original text translate text speech',\n",
              " ' environment unix toolstechnology ability engine personalize content past behavior  customer delight  reason website project  fundamental recommendation system python  intuition recommendation work basic popularity model collaborative filtering model',\n",
              " ' event message display channel selection android application graphical user interface userit act front end user interface hardware drdothis hardware streaming content  kernel module android terminalthe android app content  kernel module android terminalthe android app content kernel module  user app main componentsamodule device authentication bmodule channel program listingcmodule display alert message streaming content',\n",
              " ' facial expression recognition task expression face image various category anger surprise  convolution neural network cnn technique two cnn model vgg deep convolution network test accuracy  mini exception model embed device test accuracy  framework keras language python',\n",
              " ' passenger airport virtual queue system wait time various queue airport automatic detection presence iot php mysql beacon html javascript',\n",
              " ' financial institution significant loss default vehicle loan tightening vehicle loan underwriting increase vehicle loan rejection rate need better credit risk scoring model institution study determinant vehicle loan default task probability loaneeborrower vehicle loan first emi monthly instalment due date base information loan loanee task  catboost algorithm',\n",
              " ' first mile logistic movement productsshipment retailer client processing centre project task volume shipment client warehouse give day future planning optimise vehicle route first mile pickup number package client warehouse physical volume package write code python dataset detail past pickup  basis similarly behave client warehouse  model segment account different feature number package typical volume package',\n",
              " ' idea hypertension risk prediction system improve sparse logistic model relevant feature electronic health record ehr deep neural network dn and prediction hypertension risk',\n",
              " ' futurister application tourist part project fundamental concept material design android',\n",
              " ' new frame consecutive frame video increase frame rate video slow motion video frame recovery deep learning optical flow contextual feature complex motion',\n",
              " ' timetable erp  google calendar automation tedious task',\n",
              " ' gradle joke joke android application part android nano degree part project joke google cloud endpoint depth gradle different flavor application gradle sign apk gradle gradle console',\n",
              " ' store specific attribute pre post analysis difference sale rate attribute anova technique mean sale rate different grouping variable',\n",
              " ' entire coding be rd product intense computation fraction time crisp analysis end user  entire road map madvisorthis product automated insight predictive analytics solution domain  data scientist entire algorithm be product',\n",
              " ' handwritten lexer parser cpython project internal implementation parser lexer compiler  part compiler design subject  completely handwrite lexer c c language technique word building  language parser lr python  parse table lr set item give grammar code  best feature least number line',\n",
              " ' ecological restoration village pond adopt village meerpur bahadrabad black distt haridwar uttarakhand india help various environmental consultancy jm envirotechwrote newspaper article media outlet awareness work uba iit roorkee report initiative',\n",
              " ' organization user transaction patter and term day week day month result growth high rate',\n",
              " ' user  transaction cycle retention',\n",
              " '  image goal weather give image cat',\n",
              " ' hyper local delivery hld item merchant item customer optimum turn around time tatthe first part project tat statistical distribution time day distance parameter similar order arrival traffic condition estimate tat clusterthe second part project number delivery staff hour day average tat day average tat hour give time range approach deterministic model initial guess number delivery staff initial guess optimum number hour',\n",
              " '  convolutional neural network cn and keras scratch facial expression data x pixel grayscale image face objective face emotion facial expression seven category surprise  opencv face image bounding box  cn and  train model web interface real time facial expression recognition video image data',\n",
              " '  recurrent neural network name entity recognition ner problem ner common task natural language processing system  extraction entity text person organization location task  name entity twitter',\n",
              " '  unet neural network architecture segment human noisy background imagedataset',\n",
              " '  two different approach time series forecasting takagi sugeno et fuzzy model ann two different method account different characteristic approach',\n",
              " '  python language bottle server rest api download audio youtube people  music much bandwidth',\n",
              " '  project human voice separation various background noise smartphone vehicle part project  multiple deep learning model traffic noise music passenger voice  dataset model',\n",
              " '  autoencoder symmetric feedback connection image accuracy vgg captcha face emotion recognition extremely noisy image',\n",
              " ' ibm office worker we city  build related issue elevator wait time  cumulative time office worker elevator past month new york year los angeles year',\n",
              " ' customer  usual shopping gap  retention strategy predictive model risk attrition modeling methodology accelerate failure time data preparation modeling tool sql sas',\n",
              " ' question quora duplicate question answer question  pair question duplicate',\n",
              " ' image retrieval hand free sketch amateur interesting challenging problem project siamese network similarity sketch photo pair give sketch model closely match photo large image dataset',\n",
              " ' image super resolution resolution image generate pixel give low resolution require high resolution image  deep learning base model purpose large amount diverse data model model keras interface project inter and prof v subramanyam iiit delhi',\n",
              " ' implementation research paper two stream convolutional network action recognition video httpsarxivorgpdfpdf keras scikit',\n",
              " ' c application informal email formal email sentimental analysis dataset word usage formal informal email word replacement operation word wordnet api high success rate around usage correct word email',\n",
              " ' cnn model research paper nvidia steer angle gas break car emulator space footage camera simulator',\n",
              " ' compiler c like toy language front end back end module lexer parser semantic analyser assembly code generator c',\n",
              " ' evolutionary swarm robotics algorithm c ros swarm behaviour gazebo',\n",
              " ' generative adversarial network model image mnist dataset conditional gan class specific image project tensorflow nvidia gtx',\n",
              " ' facenet neural net architechture live face detection recognition webcam feed use tensorflow opencv python',\n",
              " ' implement mask be cnn model image segmentation vehicle uav video model image model vehicle high accuracy uav software stack',\n",
              " ' state art deep learning model dmn question fb babi dataset positional encoding paragraph bidirectional gru paragraph representation episodic memory module attention memory paragraph question answer module xcnal memory representation question answer model end deep learning framework pytorch',\n",
              " ' state art deep learning model model fact document hierarchical structure collection word sentence collection sentence document attention mechanism word sentence level precise document representation',\n",
              " ' implement style transfer focus human figure image flask deeplab model semantic image segmentation human figure option styling complete image human figure image',\n",
              " ' svm random forest news article two class feature selection bic',\n",
              " ' paper word translation parallel data  concept cycle gans another generator discriminator target source cluster similarity language  multiple model cluster',\n",
              " ' two different model rnn rgn part literature review ab initio protein structure prediction devise method protein data train test validation set clustering evolutionary relationship data',\n",
              " ' go food search team relevant personalise food search result user  restaurant dish  rank elasticsearch list result basis user interaction history brand merchant cuisine',\n",
              " ' challenge  analysis sort people  tool passenger tragedy',\n",
              " '  first app also website student  th standard bachelor degree  free online course',\n",
              " ' project algorithm base method fault inverter grid three phase voltage source inverter vsi fsm fft base algorithm fault igbt dc bus lcl filter inverter algorithm hybrid board fpga dsp platform lab prototype',\n",
              " ' project  banking function purpose method bank account new user purpose method amount account transactionbank purpose method amount one user another user method account balance user amount user bank much debt  much loan user bank',\n",
              " ' project  novel framework generation greeting card deep learning next major upcoming festival current model festival diwali halloween valentine day independence day christmas end  neural style transfer coverbackground image greeting card lstm model text poetry story festival order text festival  augment reality personalize greeting video choice card feature final greeting card',\n",
              " ' project  decision tree random forest model scikit learn python employee churn prediction application  project github link',\n",
              " ' project  vehicle  type car bus truck etc project  faster rcnn algorithm cnn base algorithm',\n",
              " ' project  image artificial neural network mlp model  image convolution neural network  comparison ann cnn architecture',\n",
              " ' project aim large neural network  accuracy neural network  pruning sparsity network neural network layer pruning way weight pruning individual weight weight matrix connection neuron consecutive layer sparsity k  individual weight weight matrix with magnitude absolute value smallest k unitneuron pruning entire column weight matrix effect correspond output neuron sparsity k  column weight matrix l norm neuron smallest k  sparsity network task performance accuracy sparsity plot weight pruning neuron pruning',\n",
              " ' industrial production electric gas utility year input factor stationarity data roll statistic adcf trend estimation decomposition seasonal trend arima model predict result',\n",
              " ' information retrieval course project prof pawan goyal word mover distance tags question quora python nltk gensim library',\n",
              " ' work dylan clendenin pythona c port faker library pythonthe faker library faker data fake name fake city adress phone number email building test bench key user attribute',\n",
              " ' coding tool reimbursement calculator regulation maximum compliance reimbursementmy role requirement user story develop data access layer store procedure various data item automated unit test case method',\n",
              " ' integration follow algorithm list  algorithm algorithm multiple area machine learningclassificationcluster regression techniqueslineargenralised linear doe technique distribution plot data generation different visualisation glyphsscatter plotspiebar chart',\n",
              " ' inter iit tech meet national competition iit event software development  android app emergency  gold event',\n",
              " ' interactive media vr storytelling platform be generate prompt engage gameplay environment coordinate curiosity',\n",
              " ' internal training project university applicationmy role business logic data access layer entity framework sql server  various logic validation business layer data base access method entity framework university application submission system automated unit test method m test',\n",
              " ' introductionimage caption generator task computer vision natural language processing concept context image  natural language englishtechnique use project  deep learning technique convolutional neural network type recurrent neural network lstm togetherthe image feature xception cnn model imagenet dataset  feature lstm model image caption',\n",
              " '  information blood donor blood bank bottle blood  better way system two category people user admin user system blood request blood admin user information request functionality dynamic data structure link list array list java programming language ease user graphical user interface gui system',\n",
              " '  small micro hydroelectric powerplant area low altitude high running velocity river water we potential electricity',\n",
              " '  smart antenna system antenna programming tinker board  project rebecca technology',\n",
              " '  online food ordering system functionality customer restaurant order feedback  software engineering principle database management concept front end html css backend django',\n",
              " '  online shopping website flipkart snapdeal advantage site consumer convenience shopping facility product service different vendor contribution core developer team exist system support exist service client technical environment jse jsp strut javascript mysql tomcat role front end developer database',\n",
              " '  employee amazon  ',\n",
              " '  autonomous robotmaze solver black line white surface ir sensor array   bot technical fest iit kanpur autonomous bot competition use component microcontroller atmega voltage regulator ir sensor array embed c programming ',\n",
              " '  rotten tommato movie review dataset goal project category review',\n",
              " ' itisalegalsearchengineforlawexpertsand common people semantic search query natural language google pre train nlp model bert',\n",
              " ' loklak open source project fossasia voluntary project android application loklak loklak distribute social media message search server message various source tweet youtube description social media source',\n",
              " ' low birth weight lbw sensitive indicator socio economic condition health mother child baby birth weight less g period gestation low birth weight lbw baby india baby half lbw newborn full term baby  context present study effect various socio economic maternal risk factor birth weight institutionally deliver newborn smoking habit mother antenatal care hypertension history premature labor major factor low birth weight lbw newborn factor hypertension age mother weight last menstrual period study woman reproductive age year lbw baby way factor health mother quality antenatal care ignorance care  healthy outcome result study agreement many similar study major health factor outcome pregnancy hypertension condition major cause disease expectant mother baby one incidence prenatal morbidity mortality',\n",
              " ' image de noising web application cbdnet architecture major project custom gaussian noise add image',\n",
              " ' sparse data tail query good data head query better search result tail query',\n",
              " ' measure speed car ldr light source raspberry pi  speed car  opencv face driver number plate car  system server',\n",
              " ' method smbg data set hypoglycemia event next hour svm nn rf problemmethod cgm data set future blood concetration kalman filter early hypoglycemic alarm',\n",
              " ' microscopical application high detailing analysis large pattern single magnification project detailed image microscope  image we large pattern analysis',\n",
              " ' miko companion robot face user   system dlib machine learning library c better performance machine learning traditional face recognition system',\n",
              " ' mixture density network mdns interesting way multimodality input output one many relationship scenario output  probability distribution output weigh mixture several gaussian  actual output project  univariate bivariate mdn python tensorflow',\n",
              " ' movie recommendation system content base filtering python content base filtering approach series discrete characteristic item order additional item similar property',\n",
              " ' dissertation lhc workload hpc facility application hpc high performance computing data science technique particle physicslhc large hadron collider cern facility geneva  unstructured data simulation log file python cause bottleneck code  large scale archer uks national supercomputing facility attempt work application bottleneck project collaboration epcc edinburgh computing centre particle physic experiment university edinburghthis dissertation cern presentation',\n",
              " ' objective tags content question stackoverflow',\n",
              " ' objective project simulation model matlab dixbfferent controller speed dc motor full variable load',\n",
              " ' performance mutual fund house change aum nav growth change various factor age fund house macro economic parameter performance',\n",
              " ' flexion data various symbol gesture sensor model word sentence sequence hand gesture accuracy ',\n",
              " ' one key challenge mvcc two concurrent write operation transaction first write operation transaction rollback system start time transaction purpose',\n",
              " ' operating system unix toolstechnology python machine learning pandas sckit learn numpy plotly description sentiment analysis  insight consumer reaction announcement opinion product brand opinion event   tweet query term negative positive sentiment  training dataset twitter positive negative tweet  twitter happy sad emotion',\n",
              " ' operational performance improvement solution hospitalsi ui screen calculation logic criterion selection store procedure report generation xml xslt transformation technique datasimplemented web service cognos sdk cognos server report',\n",
              " ' two third  food go food text search search engine two primary task retrieval document  order relevance rank extremely important part search experience query searcher exactly  forgo food elasticsearch restaurant dish index  exact partial text match fuzzy matchesin order holistic search experience personalise search result restaurant dish  user  query semantic engine  concept query understanding semantic neighbour query  focus search process recall search resultsthis search history conjunction internal food database embedding query semantic component part query semantic engine correction intent classification query expansion autosuggest autocomplete knowledge graph',\n",
              " ' ps subsidy inc subsidy individual income subsidy inc authenticate data individual income demographic parameter financial parameter subsidy inc we income classifier individual suggest solution knn algorithm accuracy increase efficiency model logistic regression ',\n",
              " ' palan shopping app  e commerce app user various product application three category namely woman man accessory  instamojo payment gateway user item image  availability application convolution neural network model',\n",
              " ' parameter variation lcl filter variation time frequency response time variation step response voltage current frequency response fft impulse response capture response data parameter variation',\n",
              " ' detailed comparative analysis case single reviewer peer review process multiple reviewer involvedcreat framework genetic algorithm reviewer reviewer multi reviewer system reviewer group  case journal higher energy physic',\n",
              " ' exploratory analysis unequally distribute data feature dependence target variable classifier ann weight loss function l regularization sincere customer bank training accuracy model fold cross validation average accuracy  auc value roc curve',\n",
              " ' text generation question answer system performance various algorithm squad dataset bert model',\n",
              " ' design gyroscope single degree freedom tilt angle bicycle chassis gyroscope commonly availabe bicyle actuate steering system integrate electric motor rear wheel autonomous navigation inter hall hardware modelling event',\n",
              " ' postinger full feature blogging app login logout password post post tech stack frontend html css bootstrap backend python flask gunicorn',\n",
              " ' moisture  ash  volatile matter  fix carbon  heating value coal absorbance spectral data spectral feature convolutional neural network cn and resnet ml algorithm svm elm random forest prediction analysis model spectral feature data traditional coal analysis method unparalleled advantage term time cost accuracy',\n",
              " ' particular customer high risk higher businessrisk coefficient chance customer platform',\n",
              " ' electronic continuance indian industry bayesian structural equation modelling sem winbug analyse three different form linear sem technology acceptance model generate joint posterior distribution model parameter latent variable prior distribution winbug mcmc method perceive complexity e procurement continue usage credible interval  bayesian estimation gibbs sample winbug',\n",
              " ' average salary data scientist skill set experience work location factorsproject involved data importing data cleaning analysis prediction',\n",
              " ' prediction kinship relationship people pair image model two people image face develop siamese convolutional neural network base model feature extraction dense layer top  binary classification hyperparameters accuracy face wild dataset frameworkslibrary tensorflow keras pandas',\n",
              " ' new link node friend suggestion topological feature naive bay classifier exist non exist link',\n",
              " ' premiere application movie  top rate popular movie help tmdb api part project efficient network call android json android realm database android efficient ui component',\n",
              " ' limestone borehole data set collar data rock feature block model cambodian mine extrapolation technique',\n",
              " ' raw text data wide range nlp technique qa lstmcnn model best answer candidate query secure th position team leaderboard mrr evaluation dataset',\n",
              " ' principal investigator prof shahid abdulla information system iim k tic tac toe be programming original be implementation nicholas proelloch be library  human opponent simple move  performance original reward structure we win rival data analysis reward structure move advanced excel technique application task reinforcement learning deep learning algorithm game',\n",
              " ' prof mitra social media actionable insight disaster scenario micro blogging twitter category need availability tweet nltk lucene use classification task',\n",
              " ' service client file cloud consistency transparency use remote procedural call grpc two phase commit reliability also crash recovery case server failure code java',\n",
              " ' project dl base ada module deployment real time scenariosmy work model training inference evaluation optimal model right trade speed performance python script day day task team member independent task exist logic improvement',\n",
              " ' project scope digital marketing activity drive sale channelsthis analysis allocation maximum impact last click attribution sem model indirect impact media channel accurate attributionmodeling methodology mix modeling data preparation modeling tool sas',\n",
              " ' python nlp random forest naive bay svm project keyword database twitter data sentimental analyse market behaviour stock price project python language',\n",
              " ' recurrent neural network generative modelsi build lstm recurrent neural network python keras scratch text text training book shelock holm hound baskeville  book  new chapter book lstm modelin project  lstm network sequence character shelock holm hound baskeville  new sequence character the model epoch minute epoch single gpu',\n",
              " ' red zone deep neural network nodejs socketio  source destination user input model route user city redrisk',\n",
              " ' vec algorithm wordvec modular dry code future vec algorithm part gensim version ',\n",
              " ' reproduce state art result quora question pair task pre train bert model',\n",
              " ' research project object oriented analysis design propose method criterion relation use case software cost estimation literature survey propose method improvement date use case point method fuzzy logic technique suggest improvement exist approach software cost estimation fuzzy approach carpool application android php mysql estimate software cost propose method effectiveness',\n",
              " ' research two new algorithm semi supervise unsupervised algorithm wsd development generic framework faster plug use system wsd domain adaptation language adaptation technique word sense disambiguation earlier publication',\n",
              " ' responsibility monitoring evaluation feed various uk partner regular basis data various partner standard yahoo object depth breadth matrice accuracy datatechnology java pig hadoop big data',\n",
              " ' development part project multimedia message pc server android device php mysql server side development java android development designer project step formal software development process',\n",
              " ' resumeme best resume maker app video  job application   personality recruiter platform communication presentation skill  mock video  answer confidence  feature run text ongoing video video resume  video respective company   resume',\n",
              " ' refrigerator truck india food loss use cycle suitable condition agricultural transport design inherent air current motion truck  max efficiency',\n",
              " ' rnn input sentence word word obstacle parallelization process google transformer ip word parallel  idea  semi autoregressive model parallelization input output word',\n",
              " ' robot direction hand gesture axis accelerometer sensor embed system principle',\n",
              " ' patch basic linux real time work feature rtpreempt enhancement feature memory allocation startegyincrease determinism predictability memory allocation compactionevent drive approach',\n",
              " ' return origin customer time delivery original pickup location task client shipment high chance customercleaned pre process data feature raw data combination feature customer behaviour shipment attribute client characteristic decision tree regression model categorical continuous feature probability rto historical data customer',\n",
              " ' instagram reactjs reduxj u picture picture',\n",
              " ' secure th position leaderboard challenge type expect answer input question natural language text format  input feature head word detection pos tagging tf idf vector representation classifier svm logistic regression multi layer perceptron ensemble',\n",
              " ' secure nd rank vernon fenwickgiven  axahyperpartisanxaargumentation  unreasoning allegiance one party faction person',\n",
              " ' secure rd rank team solomonlab samsung research institute bangalorethe task two subtask question factual information opinionadvice subtask answer factual question proper answer',\n",
              " ' car fascinating technology modern world entire process surroundings car first step detection lane vehicle road project  one popular game nfs opencv python',\n",
              " ' sentiment analysis challenging subject machine learning label data set million tweet two category cn and pre train word embedding task for score performance model',\n",
              " ' several approach understanding convolutional network fact neural network model guide backprop relu addition  simple backprop  negative gradient negative gradient particular relu neuron state neuron negative influence class ',\n",
              " ' skill set jersey framework scala kafka storm druid aerospike spark aws core functionality project analytics web page user device detail geographical detail code snippet web page analytics  user data ui server side application knowledge base user segmentation classification user preference',\n",
              " ' skill set jersey framework weka deeplearningj docker project italian article interactive advertising bureau iab standard taxonomy data mining scraping technique data online source model wordvec random classifier model',\n",
              " ' skill set scala framework mysql solr aws docker cralwing website content website source truth frog cralwer result crawler best result data page solr  analysis purpose',\n",
              " ' skill set scala spark kafka mongod b hbase cassandra mysql tracker base preparation knowledge base ad network go user analytics spark server side application knowledge base user segmentation classification user preference',\n",
              " ' skill set symfony framework ad server dashboard ad tags revenue report ad publisher major client  core php  symfony framework',\n",
              " ' software java buy sell restaurant item management programming language java java swingon netbeans ide data  mysql database',\n",
              " ' speaker diarization process input audio speaker homogeneous region speaker identity   audio conversation apriori information number speaker conversation input audio unsupervised mannerthe system statistical model hmm gmm bottom agglomerative clustering  nist rich transcription dataset meeting recordings dairization error rate der two pass information bottleneck base speaker diarization system meet specific ann base feature attempt system distinct sound record audio conversation marmoset call error rate cer',\n",
              " ' stackoverflow assistant bot dialogue chat bot answer programming related question stackoverflow dataset chit chat dialogue non programming related question',\n",
              " ' stockhawk stock market analyzer application android part project advanced widget production app functional state common error case accessibility localization feature android',\n",
              " ' application neural turing machine alex grave et al torch two architecture lstm gru controller',\n",
              " ' various way community give graph modularity community structure network community structure network',\n",
              " ' basic concept behavioural finance evidence indian equity market event study analysis sas software abnormal return different company indian equity market financial data analysis ',\n",
              " ' smart india hackathon ministry electronics information technology model surveillance analysis deep learning model anomalous event  training relevant authority',\n",
              " ' video content relevant caption semantic information follow paper we model semantic relaiton effort background information exist train model',\n",
              " ' summer internship project class real time desire response dynamic control system system model autonomous helicopter',\n",
              " ' system world web mobile application interactive graphical user interface security feature rfid card password door unlocking person counter intrusion detection technique fire alarm alert user security breach email notification website mobile app system cmxcmxcm box huge potential elderly disable people routine life',\n",
              " ' dataset analysis hypothetical sample mushroom species logistic regression approach mushroom sample health',\n",
              " ' year mate  pslbm technovation annual fest college program pslbm cheap version exist beacon moduleit  remote area smartphone gps system app smartphone  location module usb module arduino transmission module  morse code person',\n",
              " ' technology verilog matlab programming language fpga zynq float point unit software ise design suit matlab awith hdl coder summary  matlab program eigenvalue eigenvector dimensional grayscale image  hardware descriptive language verilog outcome  image',\n",
              " ' term project genetic algorithm prof nirupam chakraborti cnn architecture vanilla genetic algorithm smaller dataset mnist cifar higher accuracy generate structure task large scale ilsvrc dataset',\n",
              " ' aim project curve skeleton structure object visual hull  approximation visual hull object set projection different point view medial axis silhouette spatial position stereoscopic match correspond voxel regular grid spurious vote grid  visual hull',\n",
              " ' aim project road detection satellite image variant deep convolutional neural network cnns u net output model segmentation mask road terrain',\n",
              " ' aim work methodology whose implementation company institution another person cost new dimension communication system gprs telecom service provider cost communication help system enhance security feature hassle free safe communication person mobile data image video distant friend',\n",
              " ' credit card fraud data set collection transaction european credit card september fraudulent transaction  highly imbalanced data setthe objective classifier give transaction notmy work minority class size majority class lag feature final model logistic regression model l regularization auc score use python pandas sklearn challenge',\n",
              " ' data information default payment demographic credit data history payment taiwanese credit card user april september data set  case credit card defaultmy work random forest classifier feature importance engineering important feature final random forest classifier auc score project mlr package be',\n",
              " ' data set collection approximately newsgroup document different newsgroup preprocessing document implementation classifier scratch result inbuilt sklearn classifier',\n",
              " ' digit recognition project data mnist dataset data image x pixel handwritten digit image recognition technique select machine learning algorithm program handwritten digit around accuracy rate select machine learning algorithm',\n",
              " ' exercise product development product planning desire idea limited resourcescapturing voice customer key performance characteristic flight airplane benchmark airplane key characteristic construction quality design best suite paper airplane',\n",
              " ' goal optimum path two specify point simulate binary occupancy grid probabilistic roadmap algorithm differential drive robot path pure pursuit controller algorithm matlabs robotic system toolbox',\n",
              " ' goal project company financial data data  numerical feature categorical featurethere firm year observation firm year observation highly imbalanced data time series data set  correct approach validation correct approach application row combination company time period  problem company lag feature chain index groupthe final model logistic regression model l regularization model auc score use python pandas sklearn challenge',\n",
              " ' case study university chicagosin patient  surgery breast cancer',\n",
              " ' idea typical shell often use command various unix system call normal unix shell  shell forking typical unix shellthe shell linux base operating system ',\n",
              " ' idea unique device user technique canvas fingerprinting evercooky flash cookie system accuracy ',\n",
              " ' model raspberry pi semiconductor gas sensor value ppm value value iot platform analysis',\n",
              " ' numerical analytical approach isotherm heat conduction problem computer gauss seidel analytical method temperature platerectangle plot python basic coding algorithm',\n",
              " ' objective current future plan media portfolio best mix mediamarkete activity marketing channelspercentage contribution various marketing activity marketing channel suitable statistical methodologymarginal return investment response curve marketing activity give periodoptimization non linear programming technique sas investment marketing channel returnsmodel methodology mix modeling data preparation modeling tool sas',\n",
              " ' objective drank driver customer  ride go jek app xgboost model historical data past behaviour driver customer app real time booking level data driver booking bookingthe first task new etl drank input data parquet file google cold storage exist postgre database etl form airflow job parquet file give day dag data  format drank scriptthe second task exist model new feature pipeline iteration cycle exist version model drawback improvement plan rewrite shift org level priority',\n",
              " ' objective project problem choice suitable parallelization strategy possible solution code population model population disease model actor patter and  c mpi two part framework actor patter and problem specific code code disease model',\n",
              " ' objective project single processor optimization molecular dynamics application c performance code recommendation final improve version code optimization code two area modification code addition compiler flag',\n",
              " ' objective project yolo base cnn pipeline object composite image multiple camera vehicle cudn and cuda backbone gpu pipeline prediction multiple image yolo voc dataset',\n",
              " ' online food delivery medium user food variety restaurant cafe food outlet one platform great ease system basic input user functionality user food ease system user different type food item vary quantity order delivery payment order wallet user hisher account functionality operation username customer',\n",
              " ' problem sentimental analysis polarity text document sentence featureaspect level express opinion document sentence entity featureaspect semi supervise learning',\n",
              " ' problem central problem rural area extortionate unemployment rate woman rural woman  farm produce eg rice vegetable rural area prey middleman  farmer shortage demand product rural area farmer distant market expenditure',\n",
              " ' process os simcard test case consolidate report  project tool task c c java domain specific language file configuration system  lot work product  variant os  test case tool stuff day  beautiful look excel report sheet many file many test case failure information reduce manual parsing log file excel sheet result nightly build dod product owner agile master everything   work tool feature code coverage os',\n",
              " ' project process fact project  various nlp technique machine reading comprehension summarization textual entailment',\n",
              " ' project editor voice project primary goal editor first idea feature emac editor extensive code base emac  editor python initial plan pyspeech library problem indian english accent  google speech api internet  google chrome native integrate speech api feature pocketsphinx',\n",
              " ' project various state art cnn model  significant modification architecture research  unsupervised clustering algorithm finding result project  transaction paper',\n",
              " ' project feature go jek app go ride go car customer specific predefin pickup point  booking large area multiple pickup spot project two part frequent pickup point gate poi language model cluster name gatewe historical booking data customer  basis polygon osm booking poi kmeans algorithm historical pickup point poi optimal value k poi elbow method stupid backoff methodthen gate  pickup note customer driver app and gram base language model phrase model vocabulary note maximum probability gate name',\n",
              " ' project huge speedup training time word embeddingsvectors popular unsupervise word vector learn algorithm facebook be research computationally intensive part algorithm cython part gensim version',\n",
              " ' project study development cycle production planning process cycle special focus tyre wheel wheeler manual bicycle step chassis complexity quality function deployment requirement analysis rear hub complexity analysis liaison diagram assembly cycle assembly wheel tyre assembly line balance wheel tyre assembly layout wheel tyre feasibility study robot manufacturing wheel tyre simulation process',\n",
              " ' project xct reconstruction comparison xct setupsthe outcome project comparative analysis xct scanner setup metrological suitability novel calibrate artefactit automated procedure optimal threshold selection setting desire inspection dimensional measurementsit industry standard metrological suitability  artefactthe project parameter threshold intensity selection dimension measurement inspection sample',\n",
              " ' project guidance nus professor ntu singapore',\n",
              " ' project hand movement accelerometer gyroscope data deep learning machine learn algorithm',\n",
              " ' purpose project two text   similarity  encorewebsmthe output similarity range two sentence  stepsfirst   registration  token one text similarity token  option token',\n",
              " ' system human face web camera store image person  person image shape another person',\n",
              " ' system control command app command form touch app screen speech command bluetooth module robot receive data arduino instruction motor driver motor driver low current control signal high current control signal purpose motor motor robot desire direction return robot information distance closest obstacle phone  certain obstacle ',\n",
              " ' task tags post stackoverflow task  multilabel classification approach linear model',\n",
              " ' work system gas leakage subscriber alarm gas supply valve primary safety measure additional functionality gsm enable sm alert system',\n",
              " ' android app list recent earthquake world we geological survey usg organization data usg earthquake api',\n",
              " ' app client  gem shop product service',\n",
              " ' capstone project april part requirement completion ibm data science professional certificate coursera',\n",
              " ' merge model image feature vector inceptionv model caption lstm layerdataset fliker k dataset',\n",
              " ' nsfw classifier website app child  io app project link detail',\n",
              " ' weather station arduino  esp wifi module weather data  website',\n",
              " ' car prototype raspberry pi  opencv lane road turn',\n",
              " ' btech final year project project  recommender system user user base collaborative filtering',\n",
              " ' bda course mini project description taiwan issue cash credit card repayment ability overuse credit card consumption accumulate heavy credit cash card debt crisis paymentit challenge default payment data instance number attribute uci ml library ml problem binary classification exploratory data analysis dimension reduction feature selection technique svm knn random forestlogistic regression ensemble method',\n",
              " ' business data analytics market basket analysis famous method association mining technique arsenal frequent pair triple product historical transaction market basket data multivariate online retail data number instance real integer value attribute uci ml repository ml problem association rule mining  frequent pair salesdata cleaning hot encoding frequent item set apriori association rule mining',\n",
              " ' personal mini projectdescription cancer tumor thousand genetic mutation challenge mutation tumor growth driver interpretation genetic mutation data data two data file one information genetic mutation clinical evidence text human expertspathologist genetic mutationsthere nine different class genetic mutation ml problem genetic variationsnine different class multi class classification problem text mining probability data point nine class log loss exploratory data analysis data munging word logistic regression hyperparameter tuning',\n",
              " ' personal mini projectdescription goal project provide pair question two question question quora duplicate question answer question pair question ml problem text classification task  duplicate question pair exploratory data analysis feature extraction advance feature fuzzy feature tf idf weight wordvec featurization ml model logistic regression linear svm xgboost',\n",
              " ' side mini project center excellence analytics idrbtdescription dataset bankruptcy prediction polish companieswe bankruptcy give independent feature data multivariate real value data set column row uci ml repository ml problem  bankruptcy independent feature data cleaning data imputation dimension reduction feature selection visualisationml model logistic regression svm random forest xgboost',\n",
              " ' model  small part master thesis research project  dbpedia data setthe dbpedia ontology data set non overlapp class dbpedia train data test data sample objective objective number cnn layer challenge task number layer cn and model accuracy certain limit   research challenge  skip connection residual block concept  facebook paper vdcnn paper  char embedding model  bilstm layer top vdcnn result  accuracy depth network accuracy  model tool  nltk cn and bilstm keras tensorflow',\n",
              " ' multipurpose project almost kind application   quality measure ivf sample failure rate  sperm motion we various quality measure health sample project  traffic density different vehicle velocity time count different type vehicle day',\n",
              " ' program image processing method plot pdf structure data tabular form',\n",
              " ' project file computer network java ftp server',\n",
              " ' project driver  project road signboard  driver',\n",
              " ' project forum student question favorite faculty faculty question',\n",
              " ' project python numpy implementation feed neural network functionality choose optimizer activation function many different parameter class neural net  type dataset gpu',\n",
              " ' project tumor brain xray image different type tumor model different type tumor coding environment approach python api  tensorflow kera api  percent testing accuracy  different trick accuracy application society radiologist lot time xray',\n",
              " ' project style transfer neural network paper',\n",
              " ' project super resolution task paper real time single image video super resolution efficient sub pixel convolutional neural network pytorch model onnx format inference onnx runtime cpusgpus',\n",
              " ' project make autonomous lab scale car vision processing vehicular controls software define networking project two car prototype vision base leader follower pipeline gpu processing',\n",
              " ' project combination high school physic html canvas simple target shooting game game  randomly occure balloon  mouse',\n",
              " ' project match network realm training data way training example class commonly occure class',\n",
              " ' project best approach portfolio risk  data mining approach classification stock cluster classification mathematical approach best stock group portfolio  criterion risk diversification portfolio cluster analysis stock portfolios cluster analysis algorithm k hierarchical two step overall risk portfolio diversification stock use parameter momentum volatility return',\n",
              " ' project matlab  computer vision toolbox road image robotics system toolbox shortest path point image',\n",
              " ' project femur length hence gestation period give ultrasound image give ultrasound image number pre processing method bilateral filtering otsus method thresholding edge detection sobels method better visual inspection analysis',\n",
              " ' project guidance mrs neelam kukreja dgm prog kdmipe ongc inter and android application employee detail ongc extra feature user app employee detail bookmark box google sign user',\n",
              " ' project environment analysis project human exoskeleton project  depth obstacle camera reconstruction disparity map',\n",
              " ' project system top space knowledge graph',\n",
              " ' project basic functionality new contact findrecommendation already exist contact trie data structure',\n",
              " ' project patient ecg value blood sugar level cholesterol blood pressure input parameter patient heart attack prediction back propagation algorithm self optimize mapping algorithm',\n",
              " ' project google custom search engine api people user experience  specific type file downloadi photoshop html css javascript google cse api blogger google font api project',\n",
              " ' project part academic curriculum  project opengl graphic library cradle work newton pendulum acceleration momentum blobby object particle motion anti gravit',\n",
              " ' project autonomously drive car solution deep learning project comprehensive collection four different vital self driving car utility follow simple road lane line detection detect highway lane line video stream opencv image analysis technique line hough detection advanced lane detection advanced lane finding algorithm distortion correction image rectification color gradient thresholding identify lane curvature vehicle displacement environmental challenge shadow pavement change traffic sign classification deep neural network traffic sign tensorflow different network architecture image validation behavioural cloning convolutional neural network end simulator tensorflow keras optimization technique regularization dropout network multiple tracksthere utility car futuresee project audrica comprehensive autonomously drive car simulate solution see project',\n",
              " ' project wide web architecture spider  python initial spider  basic crawler   entire website give url start pointthe site downloader url particular page  folder particular url name',\n",
              " ' website hoody shirt college student  php mysql',\n",
              " ' higher reliability term obstacle avoidance system uav advanced computing capability autopilot system cost  crowd computing environment be program another computer be input uav sensor telemetry link be program surround status uav case presence obstacle',\n",
              " ' data call famous library python numpy pandas matplotlib seaborn',\n",
              " ' potential vaccine covid  virus different protein chemical drug relationship unstructured biomedical corpora ner knowledge graph',\n",
              " ' housing price place numpy pandas matplotlib sklearn',\n",
              " ' tool spss minitab technique ordinal logistic regression neural network time series analysis non parametric anova',\n",
              " ' tool twitter app be python nltk technique lexicon machine learning nlp tf idf',\n",
              " ' tool matlab summary zika disease transmission model two approach deterministic model continuous time markov chain ctmc stochastic model basic reproduction ratio deterministic model ctmc model estimate likelihood extinction outbreak zika virus transmission virus person discrete time interval uncertainty  ctmc stochastic model we rate pattern time interval discrete interval previous process realistic fix scenario number case patient time period case markov chain model discrete number individual realistic choice discrete random variable we model ode model',\n",
              " ' conditional variational auto encoder multi class target categorical variable classification anomaly detection generate signal data point space dense noise sparce signal model signal noise sensor iot sensor samsung fab deployment progress',\n",
              " ' multilayer neural network seven class environmental sound urban sound dataset mfcc initial stage robust classifier environmental sound',\n",
              " ' neural network fake image sample train generative model corpus k low resolution sample image generator discriminator network dcgans quality generate image model fake image fake image convolution vae model scarce image distribution anomaly detection score',\n",
              " ' simple generative adversarial network gaussian signal vary distribution vary number hidden layer',\n",
              " ' train nb classifier data prior distribution accordance conjugate prior multinomial bernoulli distribution likelihood dirichlet beta distribution prior implement model java superior robustness multinomial likelihood accuracy ',\n",
              " ' model open price stock lstm long short term memory',\n",
              " ' model natural language processing mail',\n",
              " ' guidance professor k rao department computer science iit kharagpur data digital source customer opinion review youtube video selenium scoring method genuineness review skewness plant review feature specific review sentiment  hierarchical attention base position aware network review use kemeny young rank method output module recommendation detailed bucket report viable buying option',\n",
              " ' guidance prof debasis sengupta isi application survival analysis nonparametric testing time series forecasting time series model future sale give electronic item survival model censor repair data life distribution estimate projection future count repair give probability confidence',\n",
              " ' project  mobile application machine learning base server capability data processing user app sign google option interested movie genre python script running server user feed relevant movie user  rating server content popularity filtering new recommendation  user feedthis cycle',\n",
              " ' project employment people adopt village meerpur  employment bioga vendor repairer help khadi village industry commission kvic statutory body indian government',\n",
              " ' driver sale factor sale sale different car model drive factor',\n",
              " ' layer bidirectional lstm po tags bengali language word vector bengali language tensor flow cross different dataset different set po tags robustness model various type po tags',\n",
              " ' deep learn yolo architecture work logo image traffic sign brand logo',\n",
              " ' fasttext contextual word embedding dataset  lstm architecture efficient result',\n",
              " ' multi layer bidirectional dynamic lstm network embedding training model cornell university movie dialogue corpus dataset k conversational exchange',\n",
              " ' concept crawler input correspond output  surroundings',\n",
              " ' parallel corpus  and english french vice versa translator java average case similarity ',\n",
              " ' computer vision nlp deep learning caption image',\n",
              " ' siamese network useful information different process data form time series image respect similarity relationship  train twin neural network reference process data two process similarity score form cosine distance mse loss',\n",
              " ' weka binary classification breast cancer dataset patient breast cancer necessary step data preprocessing classification svm algorithm visualization accuracy platform python',\n",
              " ' chromosome medical diagnostic problem chromosome  overlapp chromosome fast fully automated segmentation solution certain experiment large number chromosome',\n",
              " ' way android application live update traffic bangalore area core idea life traffic user location traffic ingenious hackathon acm pesit bsc',\n",
              " '  document authentication mobile phone seamless way need new app  voice recognition software google assistant user flexibility ap plethora device user document one concise summary document one voice  use docusign template embed signing google dialogflow natural language processing technology  second place docusign best innovative use docusign esignature api',\n",
              " '  rake management system company maximum profit constraint company',\n",
              " '  supervise learning method person ngo  relevant people charity cause part udacity machine learn nanodegree',\n",
              " '  art intensity orientation political bias modern news article',\n",
              " '  molecular communication system unbounded diffusion channel model flow point transmitter spherical absorb receiver  channel model  different methodology order noise channel data drive model ann lstm model result analytical framework',\n",
              " '  software food ordering delivery system software engineering principle database management concept front end html end django sql',\n",
              " '  zika disease transmission model two approach deterministic model continuous time markov chain ctmc stochastic model basic reproduction ratio deterministic model ctmc model estimate likelihood extinction outbreak zika virus transmission virus person discrete time interval uncertainty  ctmc stochastic model we rate pattern time interval discrete interval previous process realistic fix scenario number case patient time period case markov chain model discrete number individual realistic choice discrete random variable we model ode model tool matlab',\n",
              " '  internet radio different station multicast udp data packet videoaudio tcp connection radio functionality play station option concurrent user gui content webcam',\n",
              " '  cpu scheduling algorithm java multithreading number process round robin manner fcfs manner analysis every cpu scheduling algorithm various scheduling criterion help gui java',\n",
              " '  recommendation engine system basic host user event event host engine look link',\n",
              " '  optical caracter recognition  three base model   idea config model base model artificial intelligence look link',\n",
              " '  method facial recognition system common feature reduction algorithm pca lda facial feature form eigen face fisher faceswe software pipeline local binary patter and lbp facial feature  face dataset yale yale essex',\n",
              " '  bit mip pipeline processor verilog hdl xilinx platform processor different operation operation fpga',\n",
              " ' website annual cultural sport festival smvdu shri mata vaishno devi university',\n",
              " ' winner event kshitij asias largest techno management fest autonomous robot image processing live video feed breakout game youngest team event participation student top institute different year study',\n",
              " ' best social impact hack major league hack california  bill amazon alexa carbon footprint digital incentive decentralize framework ethereum blockchain',\n",
              " ' overall nd runner major league hack sf hack sf state university alexa voice command casual decentralize bet friend macys product',\n",
              " ' first prize imaginghub smart home competition deephpd application use deep learning convolutional neural network gpu server raspberry pi input basler dart camera project input feed camera sum frame class label human confidence score response external circuit alert sburglar alarm application appliance',\n",
              " ' first prize microsoft garage hack gain be hackathon microsoft hyderabad campus  psychai application deep learning computer vision application microsoft stream user experience video   emotion frame emotion two crucial application visual cue comedy art diversification content people different culture',\n",
              " ' third prize image processing event kshitij participation different college student countrymade autonomous robot video feed overhead camera arena shape  priority order time runthe robot scratch arduino uno boardimplement scale rotation invariant template match technique opencv',\n",
              " ' safety analytics virtual reality savr lab project virtual environment unreal engine hospital event fire integrate knowledge modelling mesh structure fire simulation unreal enginedesigned algorithm fire simulation blueprint c basic knowledge be game design team member crowd simulation',\n",
              " ' phase  project objective propensity score model customer payment future',\n",
              " ' recommendation engine online career coaching platform collaborative content linkedin profile similarity score mentor user platform',\n",
              " ' generalize ocr various object detection character recognition algorithm yolo swt mser rcnn idea configuration scan document character detection extraction recognition toolstechnologieslibrary tensorflow opencv numpy matplotlib tabula py pytesseract',\n",
              " ' functional mapping generator cycling consistency progressive grow gans quality stability network apple orange jack fruit dataset imagenet qualitative improvement result original implementation assumption extension cyclic consistency',\n",
              " ' module localization path planning computer visionplanning localization hyper parameter ro package extend kalman filter differential drive ro base planner dynamic window approach autonomous navigation hyper parameter time elastic band base local planner roscomputer vision lane detection curve fitting lane navigation respect igvc obstacle detection avoidance svm lidar data perspective map image obstacle avoidance',\n",
              " ' frenet planner trajectory generation optimisation lqr control strategy path tracking implementation electric car mahindra eoimplement mobile net ssd real time detection traffic sign fps mx gpu pipeline end lane detection deep learning contextual aggregation network loss adversarial augmentation scheme semantic monocular road segmentation real time segmentation pipeline unstructured indian road',\n",
              " ' support system optimization various optimization technique pareto optimization optimization problem pareto frontier various set different requirement vary number variable',\n",
              " ' objective lstm model pattern past sale associate special characteristic day sale future sale',\n",
              " ' surveillance system violence crowd speak word suspect lip technique use couple cn and',\n",
              " ' guidance prof bishwabrata pradhan be i application copula theory estimation qal work use copula theory joint distribution function marginal distribution result traditional method non parametric estimation simulation estimation real life data be programming platform',\n",
              " ' back end developer team full stack responsive website cpc wb basic page  college registration form admin page website interior code',\n",
              " ' live video recordings cctv camera warning concerned person anything child',\n",
              " ' real time data correction factor friss formula indoor environment factor correction factor',\n",
              " ' team recommendation engine text analysis prof pabitra mitra',\n",
              " ' open cv video analytics accident recognition industrial area background subtraction morphological operation feature abstraction video dataset tata steel pre train mask be cn and different vehicle  contour sort multi object tracking algorithm multiple vehicle',\n",
              " ' python  retro text version classic game show wheel fortune spin traditional word guessing game multiple guess strategy computer be human project functional object oriented programming paradigm code request academic honesty policy eec dept uc berkeley',\n",
              " ' youtube sentiment analysis video view behaviour audience publisher scrape data youtube api apicall nlp approach classifier']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIfHnFb3DJ93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c5d244b-63c3-4801-fb55-c615a3dfcdfe"
      },
      "source": [
        "corpus = \" \".join(cleaned_documents).lower()\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "len(corpus) / nlp.max_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11894"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQhrHGAfDJ60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_chunk = [corpus[i:i+nlp.max_length] for i in range (0,len(corpus), nlp.max_length)]\n",
        "\n",
        "docs = []\n",
        "words = []\n",
        "nouns = []\n",
        "verbs = []\n",
        "people = []\n",
        "orgs = []\n",
        "for chunk in corpus_chunk:\n",
        "    doc = nlp(chunk)\n",
        "    docs.append(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05b8FZufDJiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "for doc in docs:\n",
        "    for token in doc:\n",
        "        words.append(token.text)\n",
        "        if token.pos_ == \"VERB\":\n",
        "            verbs.append(token.text)\n",
        "            \n",
        "        if token.pos_ == \"NOUN\":\n",
        "            nouns.append(token.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67mf5l7zCLJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "def create_bigram(tokens):\n",
        "    # Using words token generated from spacy to find bigram\n",
        "    bigrams_ = nltk.bigrams(tokens)\n",
        "    # Convert generator into list of tuples of bigram \n",
        "    return list(bigrams_)\n",
        "\n",
        "bigrams_list = create_bigram(words)\n",
        "bigrams = [\" \".join(bigram) for bigram in list(bigrams_list)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbGcELqljYv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_nouns = set(nouns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgDUUz2OCLFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05779848-276b-4910-e383-f9b89d28cb61"
      },
      "source": [
        "def get_noun_noun_bigram(bigrams):\n",
        "    \"Find bigram with both word noun\"\n",
        "    NN_bigrams = []\n",
        "    for first_word,second_word in bigrams:\n",
        "        if first_word in unique_nouns and second_word in unique_nouns:\n",
        "            NN_bigrams.append(\" \".join((first_word,second_word)))\n",
        "    return NN_bigrams\n",
        "NN_bigrams = get_noun_noun_bigram(bigrams_list)\n",
        "NN_bigrams"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['duplication task',\n",
              " 'dup algorithm',\n",
              " 'algorithm complexity',\n",
              " 'complexity time',\n",
              " 'time answer',\n",
              " 'answer number',\n",
              " 'number record',\n",
              " 'record problem',\n",
              " 'problem sort',\n",
              " 'sort neighborhood',\n",
              " 'neighborhood approach',\n",
              " 'challenge tradeoff',\n",
              " 'tradeoff precision',\n",
              " 'precision recall',\n",
              " 'score problem',\n",
              " 'problem machine',\n",
              " 'machine learning',\n",
              " 'learning technique',\n",
              " 'technique training',\n",
              " 'training data',\n",
              " 'companys performance',\n",
              " 'performance comparison',\n",
              " 'comparison peer',\n",
              " 'ratio companys',\n",
              " 'companys status',\n",
              " 'liquidity financing',\n",
              " 'financing performance',\n",
              " 'performance ratio',\n",
              " 'performer sector',\n",
              " 'result algorithm',\n",
              " 'algorithm reconstruction',\n",
              " 'reconstruction k',\n",
              " 'k space',\n",
              " 'superresolution image',\n",
              " 'sub sample',\n",
              " 'sample knee',\n",
              " 'problem video',\n",
              " 'video classification',\n",
              " 'classification basis',\n",
              " 'basis position',\n",
              " 'position camera',\n",
              " 'video frame',\n",
              " 'flow motion',\n",
              " 'motion use',\n",
              " 'use resnet',\n",
              " 'resnet classification',\n",
              " 'aim side',\n",
              " 'side project',\n",
              " 'user interface',\n",
              " 'interface experience',\n",
              " 'product aim',\n",
              " 'aim use',\n",
              " 'use case',\n",
              " 'case job',\n",
              " 'resume list',\n",
              " 'job input',\n",
              " 'web crawler',\n",
              " 'crawler job',\n",
              " 'job description',\n",
              " 'website job',\n",
              " 'job description',\n",
              " 'description resume',\n",
              " 'resume text',\n",
              " 'text mining',\n",
              " 'mining technique',\n",
              " 'model job',\n",
              " 'sign language',\n",
              " 'language sign',\n",
              " 'sign hand',\n",
              " 'pasture image',\n",
              " 'image hand',\n",
              " 'hand gesture',\n",
              " 'network image',\n",
              " 'loading data',\n",
              " 'network performance',\n",
              " 'customer level',\n",
              " 'level data',\n",
              " 'data lead',\n",
              " 'lead telecom',\n",
              " 'telecom firm',\n",
              " 'model customer',\n",
              " 'risk churn',\n",
              " 'indicator churn',\n",
              " 'value customer',\n",
              " 'customer revenue',\n",
              " 'telecom firm',\n",
              " 'firm churn',\n",
              " 'churn customer',\n",
              " 'customer service',\n",
              " 'service usage',\n",
              " 'usage build',\n",
              " 'build model',\n",
              " 'model customer',\n",
              " 'indicator churn',\n",
              " 'record task',\n",
              " 'task hand',\n",
              " 'analytics platform',\n",
              " 'platform data',\n",
              " 'base feature',\n",
              " 'feature extraction',\n",
              " 'extraction engine',\n",
              " 'engine rule',\n",
              " 'rule client',\n",
              " 'model feature',\n",
              " 'maze obstacle',\n",
              " 'obstacle video',\n",
              " 'video path',\n",
              " 'path source',\n",
              " 'source destination',\n",
              " 'author python',\n",
              " 'python library',\n",
              " 'library computation',\n",
              " 'equation ode',\n",
              " 'ode visualisation',\n",
              " 'visualisation part',\n",
              " 'summer code',\n",
              " 'test automation',\n",
              " 'automation documentation',\n",
              " 'research university',\n",
              " 'matter effect',\n",
              " 'lensing project',\n",
              " 'project python',\n",
              " 'python software',\n",
              " 'score credibility',\n",
              " 'credibility prediction',\n",
              " 'prediction event',\n",
              " 'event user',\n",
              " 'data analysis',\n",
              " 'attention network',\n",
              " 'network word',\n",
              " 'word tweet',\n",
              " 'tweet event',\n",
              " 'event level',\n",
              " 'level plan',\n",
              " 'transformer encoder',\n",
              " 'encoder decoder',\n",
              " 'decoder architecture',\n",
              " 'architecture model',\n",
              " 'model performance',\n",
              " 'end pipeline',\n",
              " 'abnormality chest',\n",
              " 'chest x',\n",
              " 'x ray',\n",
              " 'chest x',\n",
              " 'x ray',\n",
              " 'ray competition',\n",
              " 'dataset chest',\n",
              " 'chest x',\n",
              " 'x ray',\n",
              " 'ray image',\n",
              " 'image processing',\n",
              " 'processing data',\n",
              " 'histogram equalization',\n",
              " 'augmentation technique',\n",
              " 'technique classification',\n",
              " 'architecture accuracy',\n",
              " 'accuracy disease',\n",
              " 'disease ensemble',\n",
              " 'ensemble model',\n",
              " 'clustering model',\n",
              " 'model country',\n",
              " 'factor country',\n",
              " 'country focus',\n",
              " 'focus data',\n",
              " 'model outlier',\n",
              " 'outlier use',\n",
              " 'use silhouette',\n",
              " 'silhouette score',\n",
              " 'score elbow',\n",
              " 'elbow method',\n",
              " 'number cluster',\n",
              " 'country cluster',\n",
              " 'group pattern',\n",
              " 'agent soccer',\n",
              " 'environment physic',\n",
              " 'physic rule',\n",
              " 'rule soccer',\n",
              " 'level skill',\n",
              " 'skill factor',\n",
              " 'level skill',\n",
              " 'defense positioning',\n",
              " 'positioning module',\n",
              " 'point map',\n",
              " 'position goalie',\n",
              " 'goalie skill',\n",
              " 'team competition',\n",
              " 'client entity',\n",
              " 'number document',\n",
              " 'document number',\n",
              " 'number document',\n",
              " 'document document',\n",
              " 'document size',\n",
              " 'size task',\n",
              " 'task lot',\n",
              " 'lot time',\n",
              " 'time task',\n",
              " 'task name',\n",
              " 'name entity',\n",
              " 'entity recognition',\n",
              " 'recognition entity',\n",
              " 'entity disambiguation',\n",
              " 'disambiguation technique',\n",
              " 'data capture',\n",
              " 'capture analysis',\n",
              " 'analysis requirement',\n",
              " 'requirement client',\n",
              " 'analytics platform',\n",
              " 'platform data',\n",
              " 'data model',\n",
              " 'model user',\n",
              " 'data analysis',\n",
              " 'analysis visualization',\n",
              " 'visualization build',\n",
              " 'build analytics',\n",
              " 'analytics tool',\n",
              " 'tool anomaly',\n",
              " 'anomaly detection',\n",
              " 'detection duplication',\n",
              " 'data model',\n",
              " 'model project',\n",
              " 'project data',\n",
              " 'data model',\n",
              " 'model script',\n",
              " 'script data',\n",
              " 'script data',\n",
              " 'data model',\n",
              " 'model business',\n",
              " 'business problem',\n",
              " 'data exploration',\n",
              " 'exploration visualization',\n",
              " 'visualization template',\n",
              " 'template feature',\n",
              " 'feature engineering',\n",
              " 'engineering training',\n",
              " 'training anomaly',\n",
              " 'anomaly detection',\n",
              " 'detection algorithm',\n",
              " 'email address',\n",
              " 'team cause',\n",
              " 'cause delay',\n",
              " 'delay email',\n",
              " 'team person',\n",
              " 'text mining',\n",
              " 'mining pipeline',\n",
              " 'pipeline python',\n",
              " 'feature engineering',\n",
              " 'credit risk',\n",
              " 'risk model',\n",
              " 'model validation',\n",
              " 'validation engagement',\n",
              " 'engagement bank',\n",
              " 'bank engagement',\n",
              " 'engagement data',\n",
              " 'data preparation',\n",
              " 'preparation stage',\n",
              " 'stage model',\n",
              " 'model validation',\n",
              " 'validation stage',\n",
              " 'stage data',\n",
              " 'data preparation',\n",
              " 'preparation step',\n",
              " 'step creation',\n",
              " 'creation data',\n",
              " 'data requirement',\n",
              " 'requirement list',\n",
              " 'ordination client',\n",
              " 'data data',\n",
              " 'data quality',\n",
              " 'correctness data',\n",
              " 'data model',\n",
              " 'model validation',\n",
              " 'validation stage',\n",
              " 'stage implementation',\n",
              " 'model validation',\n",
              " 'validation technique',\n",
              " 'dataset record',\n",
              " 'review restaurant',\n",
              " 'restaurant data',\n",
              " 'data cleaning',\n",
              " 'cleaning data',\n",
              " 'data visualization',\n",
              " 'visualization model',\n",
              " 'model sentiment',\n",
              " 'sentiment restaurant',\n",
              " 'restaurant review',\n",
              " 'review algorithm',\n",
              " 'algorithm technology',\n",
              " 'end web',\n",
              " 'web app',\n",
              " 'link httpstinyurlcomrestaurant',\n",
              " 'httpstinyurlcomrestaurant review',\n",
              " 'review sentiment',\n",
              " 'dataset record',\n",
              " 'headline date',\n",
              " 'date data',\n",
              " 'data cleaning',\n",
              " 'cleaning data',\n",
              " 'data visualization',\n",
              " 'visualization model',\n",
              " 'model stock',\n",
              " 'stock price',\n",
              " 'price news',\n",
              " 'news headline',\n",
              " 'headline algorithm',\n",
              " 'algorithm technology',\n",
              " 'bay python',\n",
              " 'dataset record',\n",
              " 'sm message',\n",
              " 'message data',\n",
              " 'data cleaning',\n",
              " 'cleaning data',\n",
              " 'data visualization',\n",
              " 'visualization model',\n",
              " 'model sms',\n",
              " 'sms spam',\n",
              " 'algorithm technology',\n",
              " 'bay python',\n",
              " 'end web',\n",
              " 'web app',\n",
              " 'dataset record',\n",
              " 'record news',\n",
              " 'news headline',\n",
              " 'headline data',\n",
              " 'data cleaning',\n",
              " 'cleaning data',\n",
              " 'data visualization',\n",
              " 'visualization model',\n",
              " 'model news',\n",
              " 'news algorithm',\n",
              " 'algorithm technology',\n",
              " 'bay python',\n",
              " 'dataset record',\n",
              " 'record movie',\n",
              " 'movie script',\n",
              " 'script script',\n",
              " 'script word',\n",
              " 'word genre',\n",
              " 'genre data',\n",
              " 'data cleaning',\n",
              " 'cleaning data',\n",
              " 'data visualization',\n",
              " 'visualization model',\n",
              " 'model genre',\n",
              " 'genre movie',\n",
              " 'movie word',\n",
              " 'word script',\n",
              " 'script algorithm',\n",
              " 'algorithm technology',\n",
              " 'bay python',\n",
              " 'end web',\n",
              " 'web app',\n",
              " 'genre classifier',\n",
              " 'dataset record',\n",
              " 'data analysis',\n",
              " 'analysis data',\n",
              " 'data cleaning',\n",
              " 'cleaning data',\n",
              " 'data visualization',\n",
              " 'model person',\n",
              " 'algorithm technology',\n",
              " 'decision tree',\n",
              " 'forest python',\n",
              " 'end web',\n",
              " 'web app',\n",
              " 'dataset record',\n",
              " 'feature gender',\n",
              " 'gender age',\n",
              " 'income k',\n",
              " 'score data',\n",
              " 'data cleaning',\n",
              " 'cleaning data',\n",
              " 'data visualization',\n",
              " 'visualization model',\n",
              " 'model mall',\n",
              " 'mall customer',\n",
              " 'customer algorithm',\n",
              " 'algorithm technology',\n",
              " 'dataset record',\n",
              " 'feature age',\n",
              " 'data analysis',\n",
              " 'analysis data',\n",
              " 'data cleaning',\n",
              " 'cleaning data',\n",
              " 'data visualization',\n",
              " 'model person',\n",
              " 'person heart',\n",
              " 'heart disease',\n",
              " 'disease algorithm',\n",
              " 'algorithm technology',\n",
              " 'decision tree',\n",
              " 'forest python',\n",
              " 'dataset record',\n",
              " 'data analysis',\n",
              " 'analysis data',\n",
              " 'data cleaning',\n",
              " 'model chance',\n",
              " 'chance student',\n",
              " 'algorithm technology',\n",
              " 'regression lasso',\n",
              " 'decision tree',\n",
              " 'forest k',\n",
              " 'k neighbor',\n",
              " 'neighbor python',\n",
              " 'dataset web',\n",
              " 'feature job',\n",
              " 'job title',\n",
              " 'title salary',\n",
              " 'salary estimate',\n",
              " 'estimate job',\n",
              " 'job description',\n",
              " 'description rating',\n",
              " 'rating company',\n",
              " 'company name',\n",
              " 'name location',\n",
              " 'data analysis',\n",
              " 'analysis data',\n",
              " 'data cleaning',\n",
              " 'cleaning data',\n",
              " 'data visualization',\n",
              " 'visualization feature',\n",
              " 'feature engineering',\n",
              " 'model data',\n",
              " 'data scientist',\n",
              " 'scientist salary',\n",
              " 'salary algorithm',\n",
              " 'algorithm technology',\n",
              " 'regression decision',\n",
              " 'decision tree',\n",
              " 'software air',\n",
              " 'air collaborative',\n",
              " 'collaborative robot',\n",
              " 'robot position',\n",
              " 'position aeroplane',\n",
              " 'corrosion inspection',\n",
              " 'inspection body',\n",
              " 'body aeroplane',\n",
              " 'aeroplane train',\n",
              " 'train model',\n",
              " 'model predefin',\n",
              " 'predefin image',\n",
              " 'data image',\n",
              " 'image processing',\n",
              " 'software detection',\n",
              " 'shooting game',\n",
              " 'end animation',\n",
              " 'animation goal',\n",
              " 'goal score',\n",
              " 'score enemy',\n",
              " 'enemy spaceship',\n",
              " 'spaceship asteroid',\n",
              " 'base model',\n",
              " 'model information',\n",
              " 'information context',\n",
              " 'context reference',\n",
              " 'reference knowledge',\n",
              " 'answer question',\n",
              " 'question edge',\n",
              " 'edge base',\n",
              " 'base relation',\n",
              " 'relation commonsense',\n",
              " 'commonsense corpora',\n",
              " 'word vector',\n",
              " 'vector relation',\n",
              " 'research area',\n",
              " 'language processing',\n",
              " 'processing machine',\n",
              " 'machine learning',\n",
              " 'holiday dataset',\n",
              " 'dataset colour',\n",
              " 'colour histogram',\n",
              " 'histogram image',\n",
              " 'image descriptor',\n",
              " 'descriptor feature',\n",
              " 'feature image',\n",
              " 'image image',\n",
              " 'image dataset',\n",
              " 'dataset image',\n",
              " 'image descriptor',\n",
              " 'descriptor csv',\n",
              " 'csv file',\n",
              " 'file similarity',\n",
              " 'similarity image',\n",
              " 'result query',\n",
              " 'query image',\n",
              " 'network feature',\n",
              " 'content understanding',\n",
              " 'understanding image',\n",
              " 'image composition',\n",
              " 'score trading',\n",
              " 'trading strategy',\n",
              " 'market period',\n",
              " 'growth rate',\n",
              " 'rate cagr',\n",
              " 'implement accrual',\n",
              " 'anomaly trading',\n",
              " 'trading strategy',\n",
              " 'scenario cagr',\n",
              " 'testing momentum',\n",
              " 'momentum trading',\n",
              " 'trading strategy',\n",
              " 'market period',\n",
              " 'return use',\n",
              " 'database performance',\n",
              " 'performance strategy',\n",
              " 'strategy python',\n",
              " 'scrape module',\n",
              " 'module disease',\n",
              " 'information web',\n",
              " 'web media',\n",
              " 'media newspaper',\n",
              " 'classifier sentiment',\n",
              " 'sentiment analyser',\n",
              " 'analyser article',\n",
              " 'article type',\n",
              " 'type effect',\n",
              " 'effect reader',\n",
              " 'analysis data',\n",
              " 'data progress',\n",
              " 'progress modification',\n",
              " 'eradication campaign',\n",
              " 'value player',\n",
              " 'workflow player',\n",
              " 'player skill',\n",
              " 'skill skill',\n",
              " 'skill evaluation',\n",
              " 'value player',\n",
              " 'dollar problem',\n",
              " 'problem industry',\n",
              " 'skill player',\n",
              " 'time revenue',\n",
              " 'skill player',\n",
              " 'player skill',\n",
              " 'skill level',\n",
              " 'level player',\n",
              " 'game help',\n",
              " 'help camera',\n",
              " 'device cloud',\n",
              " 'step game',\n",
              " 'game building',\n",
              " 'building player',\n",
              " 'player valuation',\n",
              " 'valuation fraud',\n",
              " 'fraud detection',\n",
              " 'detection model',\n",
              " 'load server',\n",
              " 'server ipf',\n",
              " 'ipf file',\n",
              " 'file system',\n",
              " 'system model',\n",
              " 'zone city',\n",
              " 'maximum entropy',\n",
              " 'entropy model',\n",
              " 'implement baseline',\n",
              " 'baseline method',\n",
              " 'method chunk',\n",
              " 'chunk tag',\n",
              " 'tag speech',\n",
              " 'pun syntactic',\n",
              " 'task state',\n",
              " 'state art',\n",
              " 'art result',\n",
              " 'team data',\n",
              " 'data analyst',\n",
              " 'data point',\n",
              " 'source project',\n",
              " 'project task',\n",
              " 'task advance',\n",
              " 'language processing',\n",
              " 'processing technique',\n",
              " 'technique segmentation',\n",
              " 'segmentation classification',\n",
              " 'classification association',\n",
              " 'association technique',\n",
              " 'technique information',\n",
              " 'data analyst',\n",
              " 'analyst training',\n",
              " 'training model',\n",
              " 'model accuracy',\n",
              " 'machine learning',\n",
              " 'learning technique',\n",
              " 'life scenario',\n",
              " 'repository data',\n",
              " 'regression algorithm',\n",
              " 'algorithm dimensionality',\n",
              " 'dimensionality reduction',\n",
              " 'reduction technique',\n",
              " 'time data',\n",
              " 'data readmission',\n",
              " 'patient classification',\n",
              " 'classification algorithm',\n",
              " 'forest classifier',\n",
              " 'prediction interval',\n",
              " 'interval novel',\n",
              " 'novel attention',\n",
              " 'attention base',\n",
              " 'time series',\n",
              " 'series model',\n",
              " 'test sample',\n",
              " 'sample model',\n",
              " 'model month',\n",
              " 'month run',\n",
              " 'run simulation',\n",
              " 'simulation control',\n",
              " 'control loop',\n",
              " 'loop trip',\n",
              " 'trip logic',\n",
              " 'logic equipment',\n",
              " 'equipment understudy',\n",
              " 'alarm program',\n",
              " 'savings deployment',\n",
              " 'deployment module',\n",
              " 'module term',\n",
              " 'term shutdown',\n",
              " 'shutdown avoidance',\n",
              " 'work network',\n",
              " 'network embedding',\n",
              " 'embedding network',\n",
              " 'network structure',\n",
              " 'structure user',\n",
              " 'network representation',\n",
              " 'representation project',\n",
              " 'network node',\n",
              " 'node latent',\n",
              " 'space mind',\n",
              " 'mind follow',\n",
              " 'follow property',\n",
              " 'property embedding',\n",
              " 'embedding structure',\n",
              " 'structure network',\n",
              " 'network embedding',\n",
              " 'embedding account',\n",
              " 'account user',\n",
              " 'content attribute',\n",
              " 'attribute node',\n",
              " 'node learn',\n",
              " 'learn node',\n",
              " 'node representation',\n",
              " 'representation scale',\n",
              " 'property network',\n",
              " 'contact channel',\n",
              " 'channel dialler',\n",
              " 'dialler email',\n",
              " 'challenge cost',\n",
              " 'impact money',\n",
              " 'money customer',\n",
              " 'algorithm clustering',\n",
              " 'clustering collaborative',\n",
              " 'collaborative filtering',\n",
              " 'filtering sequence',\n",
              " 'sequence mining',\n",
              " 'mining goal',\n",
              " 'event payment',\n",
              " 'payment data',\n",
              " 'data tool',\n",
              " 'tool spark',\n",
              " 'spark hive',\n",
              " 'lead contributor',\n",
              " 'contributor python',\n",
              " 'python library',\n",
              " 'python problem',\n",
              " 'problem orbit',\n",
              " 'orbit propagation',\n",
              " 'propagation solution',\n",
              " 'problem conversion',\n",
              " 'conversion position',\n",
              " 'position velocity',\n",
              " 'velocity vector',\n",
              " 'element orbit',\n",
              " 'contribution api',\n",
              " 'api design',\n",
              " 'design plot',\n",
              " 'plot module',\n",
              " 'module addition',\n",
              " 'addition frame',\n",
              " 'frame reference',\n",
              " 'bug fix',\n",
              " 'linux window',\n",
              " 'window bot',\n",
              " 'bot automation',\n",
              " 'automation support',\n",
              " 'support issue',\n",
              " 'issue wrapper',\n",
              " 'query module',\n",
              " 'analysis naphtha',\n",
              " 'naphtha cracking',\n",
              " 'cracking process',\n",
              " 'process data',\n",
              " 'data haldia',\n",
              " 'dimensionality reduction',\n",
              " 'naphtha cracking',\n",
              " 'cracking processand',\n",
              " 'processand installation',\n",
              " 'monitoring sensor',\n",
              " 'data collection',\n",
              " 'box model',\n",
              " 'model naphtha',\n",
              " 'naphtha cracking',\n",
              " 'cracking process',\n",
              " 'process component',\n",
              " 'component input',\n",
              " 'input feed',\n",
              " 'feed furnace',\n",
              " 'furnace temperature',\n",
              " 'temperature fuel',\n",
              " 'fuel usage',\n",
              " 'usage percent',\n",
              " 'ensemble model',\n",
              " 'model gradient',\n",
              " 'gradient tree',\n",
              " 'output variable',\n",
              " 'image lung',\n",
              " 'lung noise',\n",
              " 'noise removal',\n",
              " 'filter gaussian',\n",
              " 'gaussian filter',\n",
              " 'filter gamma',\n",
              " 'gamma correction',\n",
              " 'correction contrast',\n",
              " 'contrast enhancement',\n",
              " 'enhancement k',\n",
              " 'k mean',\n",
              " 'mean algorithm',\n",
              " 'image segmentation',\n",
              " 'segmentation state',\n",
              " 'state art',\n",
              " 'learning architecture',\n",
              " 'lung cancer',\n",
              " 'cancer dataset',\n",
              " 'dataset dice',\n",
              " 'dice coefficient',\n",
              " 'accuracy segmentation',\n",
              " 'novel approach',\n",
              " 'approach emotion',\n",
              " 'conversation tree',\n",
              " 'tree lstm',\n",
              " 'learning model',\n",
              " 'model variation',\n",
              " 'variation tree',\n",
              " 'tree lstm',\n",
              " 'lstm behavior',\n",
              " 'bay algorithm',\n",
              " 'algorithm implementation',\n",
              " 'text insight',\n",
              " 'insight data',\n",
              " 'propose novel',\n",
              " 'novel method',\n",
              " 'dialogue system',\n",
              " 'system sub',\n",
              " 'sub problem',\n",
              " 'problem capability',\n",
              " 'encoder variation',\n",
              " 'state art',\n",
              " 'art model',\n",
              " 'model dialogue',\n",
              " 'dialogue generation',\n",
              " 'supervise graph',\n",
              " 'graph base',\n",
              " 'base approach',\n",
              " 'approach link',\n",
              " 'link prediction',\n",
              " 'web scraping',\n",
              " 'scraping algorithm',\n",
              " 'dataset edge',\n",
              " 'edge weight',\n",
              " 'semantic similarity',\n",
              " 'similarity noun',\n",
              " 'graph base',\n",
              " 'supervise method',\n",
              " 'method link',\n",
              " 'link prediction',\n",
              " 'problem learn',\n",
              " 'learn representation',\n",
              " 'representation knowledge',\n",
              " 'knowledge graph',\n",
              " 'link propose',\n",
              " 'propose improvement',\n",
              " 'model distmult',\n",
              " 'distmult transe',\n",
              " 'neighbor loss',\n",
              " 'loss representation',\n",
              " 'representation entity',\n",
              " 'entity relation',\n",
              " 'improvement state',\n",
              " 'state art',\n",
              " 'art mean',\n",
              " 'benchmark dataset',\n",
              " 'aim project',\n",
              " 'network scratch',\n",
              " 'scratch classification',\n",
              " 'classification task',\n",
              " 'class classification',\n",
              " 'classification case',\n",
              " 'case accuracy',\n",
              " 'scheme accuracy',\n",
              " 'accuracy range',\n",
              " 'range percent',\n",
              " 'regression model',\n",
              " 'model dataset',\n",
              " 'class classification',\n",
              " 'classification case',\n",
              " 'scheme accuracy',\n",
              " 'accuracy scheme',\n",
              " 'aim project',\n",
              " 'value dimension',\n",
              " 'reconstruction error',\n",
              " 'error data',\n",
              " 'space accuracy',\n",
              " 'accuracy test',\n",
              " 'test set',\n",
              " 'retailer customer',\n",
              " 'customer coupon',\n",
              " 'marketing strategy',\n",
              " 'strategy technique',\n",
              " 'model data',\n",
              " 'dataset news',\n",
              " 'news article',\n",
              " 'article accuracy',\n",
              " 'accuracy improve',\n",
              " 'improve accuracy',\n",
              " 'accuracy regularization',\n",
              " 'regularization hyperparameter',\n",
              " 'hyperparameter tuning',\n",
              " 'edit distance',\n",
              " 'word word',\n",
              " 'word vocabulary',\n",
              " 'vocabulary word',\n",
              " 'word minimum',\n",
              " 'minimum edit',\n",
              " 'edit distance',\n",
              " 'distance correction',\n",
              " 'image data',\n",
              " 'data augmentation',\n",
              " 'augmentation data',\n",
              " 'data data',\n",
              " 'dataset classification',\n",
              " 'data augmentation',\n",
              " 'augmentation technique',\n",
              " 'x ray',\n",
              " 'ray image',\n",
              " 'model scratch',\n",
              " 'scratch classification',\n",
              " 'visualization validation',\n",
              " 'help doctor',\n",
              " 'doctor comparison',\n",
              " 'model technique',\n",
              " 'chest x',\n",
              " 'x ray',\n",
              " 'ray report',\n",
              " 'report model',\n",
              " 'similarity sentence',\n",
              " 'paper implementation',\n",
              " 'implementation report',\n",
              " 'report image',\n",
              " 'model report',\n",
              " 'report image',\n",
              " 'image report',\n",
              " 'learning network',\n",
              " 'network cn',\n",
              " 'learn network',\n",
              " 'network model',\n",
              " 'image classification',\n",
              " 'classification data',\n",
              " 'learning base',\n",
              " 'base workload',\n",
              " 'workload prediction',\n",
              " 'prediction model',\n",
              " 'model factory',\n",
              " 'factory worker',\n",
              " 'worker basis',\n",
              " 'workplace safety',\n",
              " 'order data',\n",
              " 'model accuracy',\n",
              " 'forest classifier',\n",
              " 'reason wastage',\n",
              " 'wastage water',\n",
              " 'water farm',\n",
              " 'model total',\n",
              " 'total cost',\n",
              " 'cost total',\n",
              " 'total return',\n",
              " 'type crop',\n",
              " 'crop role',\n",
              " 'machine output',\n",
              " 'output crop',\n",
              " 'network weightage',\n",
              " 'weightage amount',\n",
              " 'amount water',\n",
              " 'produce help',\n",
              " 'regression technique',\n",
              " 'visualisation website',\n",
              " 'accuracy parameter',\n",
              " 'bot chatbot',\n",
              " 'api call',\n",
              " 'purpose bot',\n",
              " 'restaurant discovery',\n",
              " 'discovery experience',\n",
              " 'web base',\n",
              " 'base application',\n",
              " 'waste disposal',\n",
              " 'disposal waste',\n",
              " 'waste recycling',\n",
              " 'recycling distribution',\n",
              " 'distribution information',\n",
              " 'information sensor',\n",
              " 'sensor dustbin',\n",
              " 'mation cloud',\n",
              " 'use clustering',\n",
              " 'clustering base',\n",
              " 'base algorithm',\n",
              " 'algorithm genetic',\n",
              " 'genetic algorithm',\n",
              " 'path waste',\n",
              " 'waste collection',\n",
              " 'collection center',\n",
              " 'center waste',\n",
              " 'waste fill',\n",
              " 'fill dustbin',\n",
              " 'dustbin priority',\n",
              " 'priority distance',\n",
              " 'path cost',\n",
              " 'cost distribution',\n",
              " 'distribution recycle',\n",
              " 'recycle material',\n",
              " 'android app',\n",
              " 'app drive',\n",
              " 'drive practice',\n",
              " 'practice user',\n",
              " 'user data',\n",
              " 'phone sensor',\n",
              " 'sensor accelerometer',\n",
              " 'driving practice',\n",
              " 'practice k',\n",
              " 'k mean',\n",
              " 'mean clustering',\n",
              " 'clustering algorithm',\n",
              " 'algorithm threshold',\n",
              " 'threshold event',\n",
              " 'leave turn',\n",
              " 'turn threshold',\n",
              " 'automata event',\n",
              " 'event automata',\n",
              " 'automata event',\n",
              " 'event detection',\n",
              " 'time basis',\n",
              " 'basis accuracy',\n",
              " 'accuracy android',\n",
              " 'lstm network',\n",
              " 'network word',\n",
              " 'word embedding',\n",
              " 'embedding training',\n",
              " 'genetic variationsmutation',\n",
              " 'variationsmutation evidence',\n",
              " 'evidence text',\n",
              " 'text base',\n",
              " 'data file',\n",
              " 'information genetic',\n",
              " 'genetic mutation',\n",
              " 'evidence text',\n",
              " 'expertspathologist genetic',\n",
              " 'genetic mutation',\n",
              " 'language dataset',\n",
              " 'language dataset',\n",
              " 'dataset embedding',\n",
              " 'embedding tensorboard',\n",
              " 'number generator',\n",
              " 'data decoding',\n",
              " 'decoding circuit',\n",
              " 'data basis',\n",
              " 'basis code',\n",
              " 'code verilog',\n",
              " 'robot person',\n",
              " 'person online',\n",
              " 'time tracker',\n",
              " 'situation occlusion',\n",
              " 'occlusion appearance',\n",
              " 'appearance change',\n",
              " 'change change',\n",
              " 'car hostel',\n",
              " 'hostel corridor',\n",
              " 'cloning concept',\n",
              " 'network speed',\n",
              " 'speed steering',\n",
              " 'steering angle',\n",
              " 'angle car',\n",
              " 'car project',\n",
              " 'car control',\n",
              " 'control system',\n",
              " 'system hyper',\n",
              " 'hyper parameter',\n",
              " 'parameter tuning',\n",
              " 'model purchase',\n",
              " 'purchase amount',\n",
              " 'product personalize',\n",
              " 'decision tree',\n",
              " 'tree classifier',\n",
              " 'feature customer',\n",
              " 'age gender',\n",
              " 'status city',\n",
              " 'city type',\n",
              " 'type product',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkATVhF3jz76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from collections import OrderedDict\n",
        "\n",
        "def sort_by_frequency(data,reverse = True):\n",
        "    \"\"\" \n",
        "    Function to sord the data by its frequency\n",
        "    Returns ordered dictionary\n",
        "    Default: Sort in descending order\n",
        "        \n",
        "    \"\"\"\n",
        "    data_with_freq = dict(Counter(data))\n",
        "    data_sorted_by_freq = OrderedDict(sorted(data_with_freq.items(), key=lambda x: x[1],reverse=reverse))\n",
        "    \n",
        "    return data_sorted_by_freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C38mBoE4CLCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f800dd41-8f99-4488-db1f-2ab11749354c"
      },
      "source": [
        "NN_bigrams_frequency = sort_by_frequency(NN_bigrams)\n",
        "NN_bigrams_frequency"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('machine learning', 27),\n",
              "             ('data set', 17),\n",
              "             ('data analysis', 15),\n",
              "             ('data cleaning', 14),\n",
              "             ('decision tree', 12),\n",
              "             ('language processing', 12),\n",
              "             ('algorithm technology', 11),\n",
              "             ('learning model', 11),\n",
              "             ('computer vision', 11),\n",
              "             ('part project', 11),\n",
              "             ('image processing', 10),\n",
              "             ('cleaning data', 10),\n",
              "             ('state art', 10),\n",
              "             ('pre train', 10),\n",
              "             ('android application', 10),\n",
              "             ('sentiment analysis', 10),\n",
              "             ('dataset record', 9),\n",
              "             ('data visualization', 9),\n",
              "             ('time series', 9),\n",
              "             ('android app', 9),\n",
              "             ('question answer', 9),\n",
              "             ('data preparation', 8),\n",
              "             ('analysis data', 8),\n",
              "             ('object detection', 8),\n",
              "             ('raspberry pi', 8),\n",
              "             ('html css', 8),\n",
              "             ('learning algorithm', 8),\n",
              "             ('user interface', 7),\n",
              "             ('x ray', 7),\n",
              "             ('base model', 7),\n",
              "             ('regression model', 7),\n",
              "             ('credit card', 7),\n",
              "             ('breast cancer', 7),\n",
              "             ('php mysql', 7),\n",
              "             ('learning technique', 6),\n",
              "             ('feature extraction', 6),\n",
              "             ('data model', 6),\n",
              "             ('anomaly detection', 6),\n",
              "             ('visualization model', 6),\n",
              "             ('stock price', 6),\n",
              "             ('train model', 6),\n",
              "             ('processing technique', 6),\n",
              "             ('aim project', 6),\n",
              "             ('clustering algorithm', 6),\n",
              "             ('word embedding', 6),\n",
              "             ('genetic mutation', 6),\n",
              "             ('front end', 6),\n",
              "             ('preparation modeling', 6),\n",
              "             ('modeling tool', 6),\n",
              "             ('test case', 6),\n",
              "             ('model image', 6),\n",
              "             ('skill set', 6),\n",
              "             ('hand gesture', 5),\n",
              "             ('model validation', 5),\n",
              "             ('data data', 5),\n",
              "             ('web app', 5),\n",
              "             ('data scientist', 5),\n",
              "             ('network model', 5),\n",
              "             ('base application', 5),\n",
              "             ('genetic algorithm', 5),\n",
              "             ('objective project', 5),\n",
              "             ('data science', 5),\n",
              "             ('loss function', 5),\n",
              "             ('price movement', 5),\n",
              "             ('system user', 5),\n",
              "             ('algorithm wsd', 5),\n",
              "             ('user preference', 5),\n",
              "             ('unit test', 5),\n",
              "             ('lstm model', 5),\n",
              "             ('vehicle loan', 5),\n",
              "             ('birth weight', 5),\n",
              "             ('ml problem', 5),\n",
              "             ('precision recall', 4),\n",
              "             ('job description', 4),\n",
              "             ('text mining', 4),\n",
              "             ('mining technique', 4),\n",
              "             ('model customer', 4),\n",
              "             ('project python', 4),\n",
              "             ('chest x', 4),\n",
              "             ('project data', 4),\n",
              "             ('feature engineering', 4),\n",
              "             ('end web', 4),\n",
              "             ('bay python', 4),\n",
              "             ('data image', 4),\n",
              "             ('word vector', 4),\n",
              "             ('image dataset', 4),\n",
              "             ('data point', 4),\n",
              "             ('forest classifier', 4),\n",
              "             ('collaborative filtering', 4),\n",
              "             ('process data', 4),\n",
              "             ('knowledge graph', 4),\n",
              "             ('classification task', 4),\n",
              "             ('class classification', 4),\n",
              "             ('learning base', 4),\n",
              "             ('management system', 4),\n",
              "             ('classification problem', 4),\n",
              "             ('recommendation system', 4),\n",
              "             ('test accuracy', 4),\n",
              "             ('th position', 4),\n",
              "             ('c c', 4),\n",
              "             ('face image', 4),\n",
              "             ('web application', 4),\n",
              "             ('server side', 4),\n",
              "             ('data mining', 4),\n",
              "             ('auc score', 4),\n",
              "             ('bag word', 4),\n",
              "             ('hybrid algorithm', 4),\n",
              "             ('association rule', 4),\n",
              "             ('auto encoder', 4),\n",
              "             ('language model', 4),\n",
              "             ('operating system', 4),\n",
              "             ('feature data', 4),\n",
              "             ('knowledge base', 4),\n",
              "             ('kernel module', 4),\n",
              "             ('weight matrix', 4),\n",
              "             ('traffic sign', 4),\n",
              "             ('time interval', 4),\n",
              "             ('training data', 3),\n",
              "             ('video frame', 3),\n",
              "             ('use case', 3),\n",
              "             ('network image', 3),\n",
              "             ('base feature', 3),\n",
              "             ('model feature', 3),\n",
              "             ('python library', 3),\n",
              "             ('encoder decoder', 3),\n",
              "             ('ray image', 3),\n",
              "             ('ensemble model', 3),\n",
              "             ('clustering model', 3),\n",
              "             ('name entity', 3),\n",
              "             ('regression decision', 3),\n",
              "             ('answer question', 3),\n",
              "             ('image image', 3),\n",
              "             ('dataset image', 3),\n",
              "             ('trading strategy', 3),\n",
              "             ('file system', 3),\n",
              "             ('segmentation classification', 3),\n",
              "             ('model accuracy', 3),\n",
              "             ('time data', 3),\n",
              "             ('network embedding', 3),\n",
              "             ('structure network', 3),\n",
              "             ('naphtha cracking', 3),\n",
              "             ('k mean', 3),\n",
              "             ('image segmentation', 3),\n",
              "             ('base approach', 3),\n",
              "             ('link prediction', 3),\n",
              "             ('news article', 3),\n",
              "             ('data augmentation', 3),\n",
              "             ('network cn', 3),\n",
              "             ('image classification', 3),\n",
              "             ('prediction model', 3),\n",
              "             ('regression technique', 3),\n",
              "             ('base algorithm', 3),\n",
              "             ('sensor accelerometer', 3),\n",
              "             ('lstm network', 3),\n",
              "             ('evidence text', 3),\n",
              "             ('data file', 3),\n",
              "             ('control system', 3),\n",
              "             ('hyper parameter', 3),\n",
              "             ('age gender', 3),\n",
              "             ('python numpy', 3),\n",
              "             ('network architecture', 3),\n",
              "             ('feature vector', 3),\n",
              "             ('classification model', 3),\n",
              "             ('image video', 3),\n",
              "             ('transfer learning', 3),\n",
              "             ('language c', 3),\n",
              "             ('supervise learning', 3),\n",
              "             ('cross validation', 3),\n",
              "             ('validation accuracy', 3),\n",
              "             ('software engineering', 3),\n",
              "             ('motor driver', 3),\n",
              "             ('video stream', 3),\n",
              "             ('lexer parser', 3),\n",
              "             ('project part', 3),\n",
              "             ('learning machine', 3),\n",
              "             ('model classification', 3),\n",
              "             ('face recognition', 3),\n",
              "             ('attention mechanism', 3),\n",
              "             ('dimension reduction', 3),\n",
              "             ('python pandas', 3),\n",
              "             ('pandas sklearn', 3),\n",
              "             ('tool python', 3),\n",
              "             ('wordvec model', 3),\n",
              "             ('ml algorithm', 3),\n",
              "             ('technique machine', 3),\n",
              "             ('histology image', 3),\n",
              "             ('algorithm accuracy', 3),\n",
              "             ('supervise hybrid', 3),\n",
              "             ('text speech', 3),\n",
              "             ('e commerce', 3),\n",
              "             ('side application', 3),\n",
              "             ('end user', 3),\n",
              "             ('system python', 3),\n",
              "             ('methodology mix', 3),\n",
              "             ('mix modeling', 3),\n",
              "             ('modeling data', 3),\n",
              "             ('audio conversation', 3),\n",
              "             ('wrapper class', 3),\n",
              "             ('user story', 3),\n",
              "             ('word sense', 3),\n",
              "             ('map api', 3),\n",
              "             ('machine learn', 3),\n",
              "             ('image convolution', 3),\n",
              "             ('store procedure', 3),\n",
              "             ('learning framework', 3),\n",
              "             ('cpu scheduling', 3),\n",
              "             ('scheduling algorithm', 3),\n",
              "             ('pre processing', 3),\n",
              "             ('rule mining', 3),\n",
              "             ('content base', 3),\n",
              "             ('library python', 3),\n",
              "             ('model semantic', 3),\n",
              "             ('part android', 3),\n",
              "             ('android nano', 3),\n",
              "             ('nano degree', 3),\n",
              "             ('application android', 3),\n",
              "             ('user app', 3),\n",
              "             ('client warehouse', 3),\n",
              "             ('pair question', 3),\n",
              "             ('image model', 3),\n",
              "             ('word sentence', 3),\n",
              "             ('style transfer', 3),\n",
              "             ('feature selection', 3),\n",
              "             ('search result', 3),\n",
              "             ('restaurant dish', 3),\n",
              "             ('purpose method', 3),\n",
              "             ('greeting card', 3),\n",
              "             ('programming language', 3),\n",
              "             ('goal project', 3),\n",
              "             ('weight lbw', 3),\n",
              "             ('query semantic', 3),\n",
              "             ('l regularization', 3),\n",
              "             ('marketing activity', 3),\n",
              "             ('question pair', 3),\n",
              "             ('propose method', 3),\n",
              "             ('software cost', 3),\n",
              "             ('time period', 3),\n",
              "             ('pickup point', 3),\n",
              "             ('lane detection', 3),\n",
              "             ('recommendation engine', 3),\n",
              "             ('result algorithm', 2),\n",
              "             ('web crawler', 2),\n",
              "             ('network performance', 2),\n",
              "             ('level data', 2),\n",
              "             ('telecom firm', 2),\n",
              "             ('indicator churn', 2),\n",
              "             ('analytics platform', 2),\n",
              "             ('platform data', 2),\n",
              "             ('source destination', 2),\n",
              "             ('attention network', 2),\n",
              "             ('network word', 2),\n",
              "             ('decoder architecture', 2),\n",
              "             ('processing data', 2),\n",
              "             ('augmentation technique', 2),\n",
              "             ('elbow method', 2),\n",
              "             ('number cluster', 2),\n",
              "             ('level skill', 2),\n",
              "             ('number document', 2),\n",
              "             ('lot time', 2),\n",
              "             ('entity recognition', 2),\n",
              "             ('script data', 2),\n",
              "             ('credit risk', 2),\n",
              "             ('validation stage', 2),\n",
              "             ('review sentiment', 2),\n",
              "             ('model stock', 2),\n",
              "             ('news headline', 2),\n",
              "             ('model person', 2),\n",
              "             ('forest python', 2),\n",
              "             ('model data', 2),\n",
              "             ('shooting game', 2),\n",
              "             ('image descriptor', 2),\n",
              "             ('market period', 2),\n",
              "             ('value player', 2),\n",
              "             ('player skill', 2),\n",
              "             ('skill player', 2),\n",
              "             ('system model', 2),\n",
              "             ('art result', 2),\n",
              "             ('data analyst', 2),\n",
              "             ('source project', 2),\n",
              "             ('project task', 2),\n",
              "             ('training model', 2),\n",
              "             ('dimensionality reduction', 2),\n",
              "             ('attention base', 2),\n",
              "             ('series model', 2),\n",
              "             ('embedding network', 2),\n",
              "             ('payment data', 2),\n",
              "             ('cracking process', 2),\n",
              "             ('box model', 2),\n",
              "             ('input feed', 2),\n",
              "             ('image lung', 2),\n",
              "             ('mean algorithm', 2),\n",
              "             ('learning architecture', 2),\n",
              "             ('lung cancer', 2),\n",
              "             ('cancer dataset', 2),\n",
              "             ('tree lstm', 2),\n",
              "             ('art model', 2),\n",
              "             ('graph base', 2),\n",
              "             ('semantic similarity', 2),\n",
              "             ('scratch classification', 2),\n",
              "             ('classification case', 2),\n",
              "             ('scheme accuracy', 2),\n",
              "             ('model dataset', 2),\n",
              "             ('accuracy test', 2),\n",
              "             ('test set', 2),\n",
              "             ('marketing strategy', 2),\n",
              "             ('hyperparameter tuning', 2),\n",
              "             ('edit distance', 2),\n",
              "             ('word word', 2),\n",
              "             ('image data', 2),\n",
              "             ('report image', 2),\n",
              "             ('classification data', 2),\n",
              "             ('web base', 2),\n",
              "             ('user data', 2),\n",
              "             ('automata event', 2),\n",
              "             ('embedding training', 2),\n",
              "             ('information genetic', 2),\n",
              "             ('expertspathologist genetic', 2),\n",
              "             ('language dataset', 2),\n",
              "             ('basis code', 2),\n",
              "             ('model purchase', 2),\n",
              "             ('purchase amount', 2),\n",
              "             ('feature customer', 2),\n",
              "             ('web interface', 2),\n",
              "             ('location bus', 2),\n",
              "             ('user base', 2),\n",
              "             ('user user', 2),\n",
              "             ('scale image', 2),\n",
              "             ('base line', 2),\n",
              "             ('density data', 2),\n",
              "             ('base clustering', 2),\n",
              "             ('base method', 2),\n",
              "             ('text classification', 2),\n",
              "             ('embedding technique', 2),\n",
              "             ('network classification', 2),\n",
              "             ('regularization dropout', 2),\n",
              "             ('architecture tensorflow', 2),\n",
              "             ('movie recommendation', 2),\n",
              "             ('collaborative content', 2),\n",
              "             ('system call', 2),\n",
              "             ('core functionality', 2),\n",
              "             ('remote control', 2),\n",
              "             ('learn parameter', 2),\n",
              "             ('symptom disease', 2),\n",
              "             ('data sample', 2),\n",
              "             ('ensemble technique', 2),\n",
              "             ('detection recognition', 2),\n",
              "             ('accelerometer gyroscope', 2),\n",
              "             ('video data', 2),\n",
              "             ('keyboard use', 2),\n",
              "             ('value imputation', 2),\n",
              "             ('simulation model', 2),\n",
              "             ('literature survey', 2),\n",
              "             ('survey propose', 2),\n",
              "             ('language identification', 2),\n",
              "             ('train word', 2),\n",
              "             ('vector representation', 2),\n",
              "             ('class imbalance', 2),\n",
              "             ('position leaderboard', 2),\n",
              "             ('sequence length', 2),\n",
              "             ('training example', 2),\n",
              "             ('example class', 2),\n",
              "             ('class label', 2),\n",
              "             ('student innovation', 2),\n",
              "             ('outlier detection', 2),\n",
              "             ('cancer detection', 2),\n",
              "             ('yolo algorithm', 2),\n",
              "             ('streaming video', 2),\n",
              "             ('user device', 2),\n",
              "             ('microcontroller motor', 2),\n",
              "             ('model guide', 2),\n",
              "             ('capture image', 2),\n",
              "             ('image class', 2),\n",
              "             ('input image', 2),\n",
              "             ('phone number', 2),\n",
              "             ('python class', 2),\n",
              "             ('c library', 2),\n",
              "             ('parser semantic', 2),\n",
              "             ('code generator', 2),\n",
              "             ('compiler design', 2),\n",
              "             ('data analytics', 2),\n",
              "             ('memory module', 2),\n",
              "             ('module attention', 2),\n",
              "             ('detection api', 2),\n",
              "             ('factor age', 2),\n",
              "             ('pytorch implementation', 2),\n",
              "             ('dataset data', 2),\n",
              "             ('voice command', 2),\n",
              "             ('speech command', 2),\n",
              "             ('speech recognition', 2),\n",
              "             ('resnet architecture', 2),\n",
              "             ('input data', 2),\n",
              "             ('occupancy grid', 2),\n",
              "             ('project user', 2),\n",
              "             ('user disease', 2),\n",
              "             ('website user', 2),\n",
              "             ('stock market', 2),\n",
              "             ('vector machine', 2),\n",
              "             ('performance model', 2),\n",
              "             ('feature importance', 2),\n",
              "             ('processing system', 2),\n",
              "             ('word technique', 2),\n",
              "             ('model wordvec', 2),\n",
              "             ('classification image', 2),\n",
              "             ('algorithm classifier', 2),\n",
              "             ('bay classifier', 2),\n",
              "             ('classifier python', 2),\n",
              "             ('accuracy model', 2),\n",
              "             ('wsd supervise', 2),\n",
              "             ('rank approximation', 2),\n",
              "             ('degree freedom', 2),\n",
              "             ('platform communication', 2),\n",
              "             ('image x', 2),\n",
              "             ('answer system', 2),\n",
              "             ('product feature', 2),\n",
              "             ('smartphone camera', 2),\n",
              "             ('time app', 2),\n",
              "             ('app text', 2),\n",
              "             ('face attribute', 2),\n",
              "             ('recipe api', 2),\n",
              "             ('audio speaker', 2),\n",
              "             ('input user', 2),\n",
              "             ('travel time', 2),\n",
              "             ('student performance', 2),\n",
              "             ('record audio', 2),\n",
              "             ('conversation marmoset', 2),\n",
              "             ('marmoset call', 2),\n",
              "             ('series image', 2),\n",
              "             ('classification anomaly', 2),\n",
              "             ('detection technique', 2),\n",
              "             ('review review', 2),\n",
              "             ('rating review', 2),\n",
              "             ('churn prediction', 2),\n",
              "             ('ensemble method', 2),\n",
              "             ('number plate', 2),\n",
              "             ('product recognition', 2),\n",
              "             ('layer wrapper', 2),\n",
              "             ('business logic', 2),\n",
              "             ('code base', 2),\n",
              "             ('case rhino', 2),\n",
              "             ('role requirement', 2),\n",
              "             ('requirement user', 2),\n",
              "             ('payment note', 2),\n",
              "             ('image analysis', 2),\n",
              "             ('python tensorflow', 2),\n",
              "             ('image project', 2),\n",
              "             ('sense disambiguation', 2),\n",
              "             ('management fest', 2),\n",
              "             ('brain gene', 2),\n",
              "             ('linux base', 2),\n",
              "             ('base operating', 2),\n",
              "             ('car price', 2),\n",
              "             ('regression data', 2),\n",
              "             ('tool sql', 2),\n",
              "             ('network lstm', 2),\n",
              "             ('tv script', 2),\n",
              "             ('bus location', 2),\n",
              "             ('colour shape', 2),\n",
              "             ('detection module', 2),\n",
              "             ('network tensorflow', 2),\n",
              "             ('scikit learn', 2),\n",
              "             ('classifier scratch', 2),\n",
              "             ('breast histology', 2),\n",
              "             ('network python', 2),\n",
              "             ('auc value', 2),\n",
              "             ('monitoring system', 2),\n",
              "             ('data hospital', 2),\n",
              "             ('cloud computing', 2),\n",
              "             ('information retrieval', 2),\n",
              "             ('search query', 2),\n",
              "             ('framework tensorflow', 2),\n",
              "             ('text generation', 2),\n",
              "             ('network task', 2),\n",
              "             ('part compiler', 2),\n",
              "             ('mysql php', 2),\n",
              "             ('code request', 2),\n",
              "             ('honesty policy', 2),\n",
              "             ('arm instruction', 2),\n",
              "             ('online shopping', 2),\n",
              "             ('shopping website', 2),\n",
              "             ('demand forecasting', 2),\n",
              "             ('food delivery', 2),\n",
              "             ('demand product', 2),\n",
              "             ('vision base', 2),\n",
              "             ('belt deviation', 2),\n",
              "             ('belt image', 2),\n",
              "             ('laser beam', 2),\n",
              "             ('weight loss', 2),\n",
              "             ('dating website', 2),\n",
              "             ('face mask', 2),\n",
              "             ('propose om', 2),\n",
              "             ('graph algorithm', 2),\n",
              "             ('landmark detection', 2),\n",
              "             ('learning method', 2),\n",
              "             ('batch size', 2),\n",
              "             ('size learn', 2),\n",
              "             ('learn rate', 2),\n",
              "             ('chat bot', 2),\n",
              "             ('labor statistic', 2),\n",
              "             ('risk profiling', 2),\n",
              "             ('android part', 2),\n",
              "             ('concept android', 2),\n",
              "             ('material design', 2),\n",
              "             ('design android', 2),\n",
              "             ('lstm architecture', 2),\n",
              "             ('software freedom', 2),\n",
              "             ('pos tagging', 2),\n",
              "             ('movie dialogue', 2),\n",
              "             ('website technology', 2),\n",
              "             ('technology html', 2),\n",
              "             ('collaboration platform', 2),\n",
              "             ('recognition technique', 2),\n",
              "             ('year project', 2),\n",
              "             ('resolution video', 2),\n",
              "             ('text text', 2),\n",
              "             ('unix toolstechnology', 2),\n",
              "             ('streaming content', 2),\n",
              "             ('module android', 2),\n",
              "             ('app content', 2),\n",
              "             ('expression recognition', 2),\n",
              "             ('number package', 2),\n",
              "             ('volume package', 2),\n",
              "             ('hypertension risk', 2),\n",
              "             ('sale rate', 2),\n",
              "             ('technique word', 2),\n",
              "             ('number delivery', 2),\n",
              "             ('delivery staff', 2),\n",
              "             ('x pixel', 2),\n",
              "             ('image face', 2),\n",
              "             ('face emotion', 2),\n",
              "             ('recognition video', 2),\n",
              "             ('location task', 2),\n",
              "             ('series forecasting', 2),\n",
              "             ('method account', 2),\n",
              "             ('python language', 2),\n",
              "             ('office worker', 2),\n",
              "             ('resolution image', 2),\n",
              "             ('model model', 2),\n",
              "             ('research paper', 2),\n",
              "             ('figure image', 2),\n",
              "             ('generator discriminator', 2),\n",
              "             ('model cluster', 2),\n",
              "             ('food search', 2),\n",
              "             ('method amount', 2),\n",
              "             ('user bank', 2),\n",
              "             ('sparsity network', 2),\n",
              "             ('weight pruning', 2),\n",
              "             ('individual weight', 2),\n",
              "             ('weight weight', 2),\n",
              "             ('sparsity k', 2),\n",
              "             ('column weight', 2),\n",
              "             ('faker library', 2),\n",
              "             ('data access', 2),\n",
              "             ('access layer', 2),\n",
              "             ('software development', 2),\n",
              "             ('entity framework', 2),\n",
              "             ('image feature', 2),\n",
              "             ('people user', 2),\n",
              "             ('admin user', 2),\n",
              "             ('data structure', 2),\n",
              "             ('online food', 2),\n",
              "             ('engineering principle', 2),\n",
              "             ('principle database', 2),\n",
              "             ('database management', 2),\n",
              "             ('management concept', 2),\n",
              "             ('concept front', 2),\n",
              "             ('end html', 2),\n",
              "             ('product service', 2),\n",
              "             ('developer team', 2),\n",
              "             ('service client', 2),\n",
              "             ('end developer', 2),\n",
              "             ('sensor array', 2),\n",
              "             ('health mother', 2),\n",
              "             ('lbw baby', 2),\n",
              "             ('tail query', 2),\n",
              "             ('speed car', 2),\n",
              "             ('recognition system', 2),\n",
              "             ('input output', 2),\n",
              "             ('base filtering', 2),\n",
              "             ('log file', 2),\n",
              "             ('fund house', 2),\n",
              "             ('write operation', 2),\n",
              "             ('operation transaction', 2),\n",
              "             ('search engine', 2),\n",
              "             ('search experience', 2),\n",
              "             ('semantic engine', 2),\n",
              "             ('individual income', 2),\n",
              "             ('parameter variation', 2),\n",
              "             ('frequency response', 2),\n",
              "             ('data feature', 2),\n",
              "             ('reward structure', 2),\n",
              "             ('python script', 2),\n",
              "             ('team member', 2),\n",
              "             ('sequence character', 2),\n",
              "             ('research project', 2),\n",
              "             ('cost estimation', 2),\n",
              "             ('memory allocation', 2),\n",
              "             ('data customer', 2),\n",
              "             ('web page', 2),\n",
              "             ('application knowledge', 2),\n",
              "             ('base user', 2),\n",
              "             ('user segmentation', 2),\n",
              "             ('classification user', 2),\n",
              "             ('speaker diarization', 2),\n",
              "             ('input audio', 2),\n",
              "             ('error rate', 2),\n",
              "             ('community structure', 2),\n",
              "             ('equity market', 2),\n",
              "             ('security feature', 2),\n",
              "             ('project road', 2),\n",
              "             ('communication system', 2),\n",
              "             ('set collection', 2),\n",
              "             ('lag feature', 2),\n",
              "             ('model l', 2),\n",
              "             ('score use', 2),\n",
              "             ('use python', 2),\n",
              "             ('sklearn challenge', 2),\n",
              "             ('default payment', 2),\n",
              "             ('system toolbox', 2),\n",
              "             ('firm year', 2),\n",
              "             ('year observation', 2),\n",
              "             ('device user', 2),\n",
              "             ('activity marketing', 2),\n",
              "             ('marketing channel', 2),\n",
              "             ('driver customer', 2),\n",
              "             ('parquet file', 2),\n",
              "             ('disease model', 2),\n",
              "             ('actor patter', 2),\n",
              "             ('gpu pipeline', 2),\n",
              "             ('user food', 2),\n",
              "             ('ease system', 2),\n",
              "             ('document sentence', 2),\n",
              "             ('speech api', 2),\n",
              "             ('learn algorithm', 2),\n",
              "             ('project guidance', 2),\n",
              "             ('control signal', 2),\n",
              "             ('car prototype', 2),\n",
              "             ('mini project', 2),\n",
              "             ('reduction feature', 2),\n",
              "             ('market basket', 2),\n",
              "             ('ml repository', 2),\n",
              "             ('repository ml', 2),\n",
              "             ('mini projectdescription', 2),\n",
              "             ('problem text', 2),\n",
              "             ('model tool', 2),\n",
              "             ('quality measure', 2),\n",
              "             ('processing method', 2),\n",
              "             ('type tumor', 2),\n",
              "             ('cluster analysis', 2),\n",
              "             ('ultrasound image', 2),\n",
              "             ('employee detail', 2),\n",
              "             ('user experience', 2),\n",
              "             ('drive car', 2),\n",
              "             ('lane line', 2),\n",
              "             ('optimization technique', 2),\n",
              "             ('college student', 2),\n",
              "             ('obstacle avoidance', 2),\n",
              "             ('numpy pandas', 2),\n",
              "             ('disease transmission', 2),\n",
              "             ('transmission model', 2),\n",
              "             ('reproduction ratio', 2),\n",
              "             ('model estimate', 2),\n",
              "             ('estimate likelihood', 2),\n",
              "             ('likelihood extinction', 2),\n",
              "             ('extinction outbreak', 2),\n",
              "             ('virus transmission', 2),\n",
              "             ('transmission virus', 2),\n",
              "             ('virus person', 2),\n",
              "             ('interval uncertainty', 2),\n",
              "             ('rate pattern', 2),\n",
              "             ('pattern time', 2),\n",
              "             ('fix scenario', 2),\n",
              "             ('scenario number', 2),\n",
              "             ('number case', 2),\n",
              "             ('case patient', 2),\n",
              "             ('patient time', 2),\n",
              "             ('period case', 2),\n",
              "             ('chain model', 2),\n",
              "             ('number individual', 2),\n",
              "             ('model ode', 2),\n",
              "             ('ode model', 2),\n",
              "             ('future sale', 2),\n",
              "             ('similarity score', 2),\n",
              "             ('use docusign', 2),\n",
              "             ('channel model', 2),\n",
              "             ('look link', 2),\n",
              "             ('video feed', 2),\n",
              "             ('fire simulation', 2),\n",
              "             ('copula theory', 2),\n",
              "             ('correction factor', 2),\n",
              "             ('duplication task', 1),\n",
              "             ('dup algorithm', 1),\n",
              "             ('algorithm complexity', 1),\n",
              "             ('complexity time', 1),\n",
              "             ('time answer', 1),\n",
              "             ('answer number', 1),\n",
              "             ('number record', 1),\n",
              "             ('record problem', 1),\n",
              "             ('problem sort', 1),\n",
              "             ('sort neighborhood', 1),\n",
              "             ('neighborhood approach', 1),\n",
              "             ('challenge tradeoff', 1),\n",
              "             ('tradeoff precision', 1),\n",
              "             ('score problem', 1),\n",
              "             ('problem machine', 1),\n",
              "             ('technique training', 1),\n",
              "             ('companys performance', 1),\n",
              "             ('performance comparison', 1),\n",
              "             ('comparison peer', 1),\n",
              "             ('ratio companys', 1),\n",
              "             ('companys status', 1),\n",
              "             ('liquidity financing', 1),\n",
              "             ('financing performance', 1),\n",
              "             ('performance ratio', 1),\n",
              "             ('performer sector', 1),\n",
              "             ('algorithm reconstruction', 1),\n",
              "             ('reconstruction k', 1),\n",
              "             ('k space', 1),\n",
              "             ('superresolution image', 1),\n",
              "             ('sub sample', 1),\n",
              "             ('sample knee', 1),\n",
              "             ('problem video', 1),\n",
              "             ('video classification', 1),\n",
              "             ('classification basis', 1),\n",
              "             ('basis position', 1),\n",
              "             ('position camera', 1),\n",
              "             ('flow motion', 1),\n",
              "             ('motion use', 1),\n",
              "             ('use resnet', 1),\n",
              "             ('resnet classification', 1),\n",
              "             ('aim side', 1),\n",
              "             ('side project', 1),\n",
              "             ('interface experience', 1),\n",
              "             ('product aim', 1),\n",
              "             ('aim use', 1),\n",
              "             ('case job', 1),\n",
              "             ('resume list', 1),\n",
              "             ('job input', 1),\n",
              "             ('crawler job', 1),\n",
              "             ('website job', 1),\n",
              "             ('description resume', 1),\n",
              "             ('resume text', 1),\n",
              "             ('model job', 1),\n",
              "             ('sign language', 1),\n",
              "             ('language sign', 1),\n",
              "             ('sign hand', 1),\n",
              "             ('pasture image', 1),\n",
              "             ('image hand', 1),\n",
              "             ('loading data', 1),\n",
              "             ('customer level', 1),\n",
              "             ('data lead', 1),\n",
              "             ('lead telecom', 1),\n",
              "             ('risk churn', 1),\n",
              "             ('value customer', 1),\n",
              "             ('customer revenue', 1),\n",
              "             ('firm churn', 1),\n",
              "             ('churn customer', 1),\n",
              "             ('customer service', 1),\n",
              "             ('service usage', 1),\n",
              "             ('usage build', 1),\n",
              "             ('build model', 1),\n",
              "             ('record task', 1),\n",
              "             ('task hand', 1),\n",
              "             ('extraction engine', 1),\n",
              "             ('engine rule', 1),\n",
              "             ('rule client', 1),\n",
              "             ('maze obstacle', 1),\n",
              "             ('obstacle video', 1),\n",
              "             ('video path', 1),\n",
              "             ('path source', 1),\n",
              "             ('author python', 1),\n",
              "             ('library computation', 1),\n",
              "             ('equation ode', 1),\n",
              "             ('ode visualisation', 1),\n",
              "             ('visualisation part', 1),\n",
              "             ('summer code', 1),\n",
              "             ('test automation', 1),\n",
              "             ('automation documentation', 1),\n",
              "             ('research university', 1),\n",
              "             ('matter effect', 1),\n",
              "             ('lensing project', 1),\n",
              "             ('python software', 1),\n",
              "             ('score credibility', 1),\n",
              "             ('credibility prediction', 1),\n",
              "             ('prediction event', 1),\n",
              "             ('event user', 1),\n",
              "             ('word tweet', 1),\n",
              "             ('tweet event', 1),\n",
              "             ('event level', 1),\n",
              "             ('level plan', 1),\n",
              "             ('transformer encoder', 1),\n",
              "             ('architecture model', 1),\n",
              "             ('model performance', 1),\n",
              "             ('end pipeline', 1),\n",
              "             ('abnormality chest', 1),\n",
              "             ('ray competition', 1),\n",
              "             ('dataset chest', 1),\n",
              "             ('histogram equalization', 1),\n",
              "             ('technique classification', 1),\n",
              "             ('architecture accuracy', 1),\n",
              "             ('accuracy disease', 1),\n",
              "             ('disease ensemble', 1),\n",
              "             ('model country', 1),\n",
              "             ('factor country', 1),\n",
              "             ('country focus', 1),\n",
              "             ('focus data', 1),\n",
              "             ('model outlier', 1),\n",
              "             ('outlier use', 1),\n",
              "             ('use silhouette', 1),\n",
              "             ('silhouette score', 1),\n",
              "             ('score elbow', 1),\n",
              "             ('country cluster', 1),\n",
              "             ('group pattern', 1),\n",
              "             ('agent soccer', 1),\n",
              "             ('environment physic', 1),\n",
              "             ('physic rule', 1),\n",
              "             ('rule soccer', 1),\n",
              "             ('skill factor', 1),\n",
              "             ('defense positioning', 1),\n",
              "             ('positioning module', 1),\n",
              "             ('point map', 1),\n",
              "             ('position goalie', 1),\n",
              "             ('goalie skill', 1),\n",
              "             ('team competition', 1),\n",
              "             ('client entity', 1),\n",
              "             ('document number', 1),\n",
              "             ('document document', 1),\n",
              "             ('document size', 1),\n",
              "             ('size task', 1),\n",
              "             ('task lot', 1),\n",
              "             ('time task', 1),\n",
              "             ('task name', 1),\n",
              "             ('recognition entity', 1),\n",
              "             ('entity disambiguation', 1),\n",
              "             ('disambiguation technique', 1),\n",
              "             ('data capture', 1),\n",
              "             ('capture analysis', 1),\n",
              "             ('analysis requirement', 1),\n",
              "             ('requirement client', 1),\n",
              "             ('model user', 1),\n",
              "             ('analysis visualization', 1),\n",
              "             ('visualization build', 1),\n",
              "             ('build analytics', 1),\n",
              "             ('analytics tool', 1),\n",
              "             ('tool anomaly', 1),\n",
              "             ('detection duplication', 1),\n",
              "             ('model project', 1),\n",
              "             ('model script', 1),\n",
              "             ('model business', 1),\n",
              "             ('business problem', 1),\n",
              "             ('data exploration', 1),\n",
              "             ('exploration visualization', 1),\n",
              "             ('visualization template', 1),\n",
              "             ('template feature', 1),\n",
              "             ('engineering training', 1),\n",
              "             ('training anomaly', 1),\n",
              "             ('detection algorithm', 1),\n",
              "             ('email address', 1),\n",
              "             ('team cause', 1),\n",
              "             ('cause delay', 1),\n",
              "             ('delay email', 1),\n",
              "             ('team person', 1),\n",
              "             ('mining pipeline', 1),\n",
              "             ('pipeline python', 1),\n",
              "             ('risk model', 1),\n",
              "             ('validation engagement', 1),\n",
              "             ('engagement bank', 1),\n",
              "             ('bank engagement', 1),\n",
              "             ('engagement data', 1),\n",
              "             ('preparation stage', 1),\n",
              "             ('stage model', 1),\n",
              "             ('stage data', 1),\n",
              "             ('preparation step', 1),\n",
              "             ('step creation', 1),\n",
              "             ('creation data', 1),\n",
              "             ('data requirement', 1),\n",
              "             ('requirement list', 1),\n",
              "             ('ordination client', 1),\n",
              "             ('data quality', 1),\n",
              "             ('correctness data', 1),\n",
              "             ('stage implementation', 1),\n",
              "             ('validation technique', 1),\n",
              "             ('review restaurant', 1),\n",
              "             ('restaurant data', 1),\n",
              "             ('model sentiment', 1),\n",
              "             ('sentiment restaurant', 1),\n",
              "             ('restaurant review', 1),\n",
              "             ('review algorithm', 1),\n",
              "             ('link httpstinyurlcomrestaurant', 1),\n",
              "             ('httpstinyurlcomrestaurant review', 1),\n",
              "             ('headline date', 1),\n",
              "             ('date data', 1),\n",
              "             ('price news', 1),\n",
              "             ('headline algorithm', 1),\n",
              "             ('sm message', 1),\n",
              "             ('message data', 1),\n",
              "             ('model sms', 1),\n",
              "             ('sms spam', 1),\n",
              "             ('record news', 1),\n",
              "             ('headline data', 1),\n",
              "             ('model news', 1),\n",
              "             ('news algorithm', 1),\n",
              "             ('record movie', 1),\n",
              "             ('movie script', 1),\n",
              "             ('script script', 1),\n",
              "             ('script word', 1),\n",
              "             ('word genre', 1),\n",
              "             ('genre data', 1),\n",
              "             ('model genre', 1),\n",
              "             ('genre movie', 1),\n",
              "             ('movie word', 1),\n",
              "             ('word script', 1),\n",
              "             ('script algorithm', 1),\n",
              "             ('genre classifier', 1),\n",
              "             ('feature gender', 1),\n",
              "             ('gender age', 1),\n",
              "             ('income k', 1),\n",
              "             ('score data', 1),\n",
              "             ('model mall', 1),\n",
              "             ('mall customer', 1),\n",
              "             ('customer algorithm', 1),\n",
              "             ('feature age', 1),\n",
              "             ('person heart', 1),\n",
              "             ('heart disease', 1),\n",
              "             ('disease algorithm', 1),\n",
              "             ('model chance', 1),\n",
              "             ('chance student', 1),\n",
              "             ('regression lasso', 1),\n",
              "             ('forest k', 1),\n",
              "             ('k neighbor', 1),\n",
              "             ('neighbor python', 1),\n",
              "             ('dataset web', 1),\n",
              "             ('feature job', 1),\n",
              "             ('job title', 1),\n",
              "             ('title salary', 1),\n",
              "             ('salary estimate', 1),\n",
              "             ('estimate job', 1),\n",
              "             ('description rating', 1),\n",
              "             ('rating company', 1),\n",
              "             ('company name', 1),\n",
              "             ('name location', 1),\n",
              "             ('visualization feature', 1),\n",
              "             ('scientist salary', 1),\n",
              "             ('salary algorithm', 1),\n",
              "             ('software air', 1),\n",
              "             ('air collaborative', 1),\n",
              "             ('collaborative robot', 1),\n",
              "             ('robot position', 1),\n",
              "             ('position aeroplane', 1),\n",
              "             ('corrosion inspection', 1),\n",
              "             ('inspection body', 1),\n",
              "             ('body aeroplane', 1),\n",
              "             ('aeroplane train', 1),\n",
              "             ('model predefin', 1),\n",
              "             ('predefin image', 1),\n",
              "             ('software detection', 1),\n",
              "             ('end animation', 1),\n",
              "             ('animation goal', 1),\n",
              "             ('goal score', 1),\n",
              "             ('score enemy', 1),\n",
              "             ('enemy spaceship', 1),\n",
              "             ('spaceship asteroid', 1),\n",
              "             ('model information', 1),\n",
              "             ('information context', 1),\n",
              "             ('context reference', 1),\n",
              "             ('reference knowledge', 1),\n",
              "             ('question edge', 1),\n",
              "             ('edge base', 1),\n",
              "             ('base relation', 1),\n",
              "             ('relation commonsense', 1),\n",
              "             ('commonsense corpora', 1),\n",
              "             ('vector relation', 1),\n",
              "             ('research area', 1),\n",
              "             ('processing machine', 1),\n",
              "             ('holiday dataset', 1),\n",
              "             ('dataset colour', 1),\n",
              "             ('colour histogram', 1),\n",
              "             ('histogram image', 1),\n",
              "             ('descriptor feature', 1),\n",
              "             ('feature image', 1),\n",
              "             ('descriptor csv', 1),\n",
              "             ('csv file', 1),\n",
              "             ('file similarity', 1),\n",
              "             ('similarity image', 1),\n",
              "             ('result query', 1),\n",
              "             ('query image', 1),\n",
              "             ('network feature', 1),\n",
              "             ('content understanding', 1),\n",
              "             ('understanding image', 1),\n",
              "             ('image composition', 1),\n",
              "             ('score trading', 1),\n",
              "             ('growth rate', 1),\n",
              "             ('rate cagr', 1),\n",
              "             ('implement accrual', 1),\n",
              "             ('anomaly trading', 1),\n",
              "             ('scenario cagr', 1),\n",
              "             ('testing momentum', 1),\n",
              "             ('momentum trading', 1),\n",
              "             ('return use', 1),\n",
              "             ('database performance', 1),\n",
              "             ('performance strategy', 1),\n",
              "             ...])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7RtmqBUCK-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}